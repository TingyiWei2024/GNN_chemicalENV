回归预测嵌入模式

doi: 10.1038/s41598-025-85563-5

1.  核心：Transformer+Lasso 和 Adam回归方法（Huber + Lasso）叠加在基于注意力的 Transformer 之上，因此它明确地模拟了每个预测变量（传感器测量）如何对最终预测量做出贡献。 Huber 回归残差与 Lasso 的特征加权相结合，显示每个变量如何影响“基本”目标。

2.  具体方法：

Below is a concise explanation of how the variables in the referenced paper (and in similar ML pipelines) are typically standardized and how that process helps isolate each variable’s contribution or “impact” on core (target) variables:

***

## 1. Why Standardize or Normalize Variables?

When a model—particularly one using regression (e.g., Huber or Lasso) or attention mechanisms—considers many different sensor inputs (e.g., temperature, torque, blade pitch angle, wind speed, vibrations, corrosion rate), these measurements can have vastly different scales. For example:

*   **Gearbox oil temperature** may range from 30°C to 70°C.
*   **Wind speed** might range from 0 m/s to 25 m/s.
*   **Bearing vibration** signals (in g’s or mm/s) could range from 0 to \~2–3.
*   **Corrosion rate** might be dimensionless values between 2.0 and 5.0.

Such wide variations in scale can distort a learning algorithm’s perception of which inputs are most influential. Therefore, **standardization** ensures that each feature contributes more proportionally and does not get overshadowed merely because it has a larger numeric range.

***

## 2. Common Approaches to Standardization

There are two major strategies typically mentioned in the context of wind turbine SCADA data and machine-learning pipelines:

### A. Z-Score Standardization

Often called “standard scaling,” it transforms a raw variable xx into a standardized variable zz:

z=x−μσz = \frac{x - \mu}{\sigma}

where μ\mu is the mean of the feature and σ\sigma is the standard deviation of the feature.

*   **Mean of 0** and **Standard Deviation of 1.**
*   Values above the mean become positive; values below the mean become negative.
*   Commonly used for regression-based models (including Lasso or Huber) and neural network models, because it keeps outliers somewhat in perspective while centering data at 0.

### B. Min–Max Normalization

Sometimes called “range scaling,” transforms xx into x\~\widetilde{x} in the \[0,1]\[0, 1] interval (or \[−1,1]\[-1,1] for certain variants):

x\~=x−min⁡(x)max⁡(x)−min⁡(x)\widetilde{x} = \frac{x - \min(x)}{\max(x) - \min(x)}

where min⁡(x)\min(x) and max⁡(x)\max(x) are the minimum and maximum values of the feature in the training set.

*   **All values lie between 0 and 1** (or -1 and 1).
*   Often used in deep learning contexts where activation functions assume inputs in a specific range.

Either approach can be effective. In many practical ML pipelines (including the HARO model described in the paper), **Z-score scaling** is more common because it manages outliers in a more robust way than min–max scaling.

***

## 3. Workflow for Standardizing and Assessing Variable Impact

1.  **Data Preprocessing**

    *   Collect raw sensor data (temperatures, speeds, angles, etc.).
    *   Remove or impute obvious outliers (faulty or missing signals).
    *   Apply Z-score standardization (or min–max normalization) **feature-by-feature**.

2.  **Feature Selection & Lasso**

    *   After standardization, all features are on a comparable scale.
    *   Lasso (or ARD, or any linear+regularization technique) identifies the most relevant features by driving less-influential variable coefficients down (toward zero). This helps you see which standardized variables are key drivers of the target (e.g., power output, gearbox health).

3.  **Transformer + Attention**

    *   The standardized features are fed into the Transformer network, which uses multi-head attention to learn interrelationships among sensor readings over time.
    *   Because each sensor is scaled similarly, the attention scores can reveal which (standardized) variables matter the most at each timestep.

4.  **Interpreting Impacts**

    *   Lasso coefficients: After training, whichever standardized variables have the largest (absolute) coefficients or survive the shrinkage typically have the highest impact on the target.
    *   Attention heatmaps: Transformers can show which feature/time combination the model “pays attention to” when predicting health, wind speed, or other targets.

***

## 4. Ensuring Fair “Impact” on the Base Variable

By standardizing, the model no longer “mistakes” a large numeric difference in, say, **vibration amplitude** vs. **temperature** for a difference in importance. Instead, each feature is considered **relative** to its own distribution. Hence:

*   **More Direct Comparisons**\
    Standardization ensures that the magnitude of model coefficients (in the regression part) relates more directly to the genuine influence on the base (target) variable, rather than to raw unit differences.
*   **Reduced Numerical Instability**\
    Gradient-based optimizers (like Adam) handle standardized inputs more efficiently, which helps in stable convergence.

***

### Summary

1.  **Yes, these variables are standardized** (commonly via Z-score or min–max methods) before entering the HARO model.
2.  This ensures that each sensor input is on the **same footing** when the model learns patterns.
3.  **Result**: The final model can better identify which variables (like gearbox temperature, blade pitch, wind speed) most significantly affect the target variable(s)—whether that is power output, fault detection, corrosion rate, or other key metrics.
