{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA \n",
    "1. input molecules graph data √\n",
    "2. input correct env variable √  - btw: art is what seawater?\n",
    "3. connect these data ×\n",
    "只匹配环境变量 20×16 = 320 和 1023对不上（这个因为同一环境条件下对一个分子不止做了一次实验，明天再研究下能怎么匹配），我明天再改下，\n",
    "还是得从表格取env_df\n",
    "卡住"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load molecules graph datas from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 graphs\n"
     ]
    }
   ],
   "source": [
    "## Load the molecular data (.pkl) for molecules with Targeted BDE & BDFE \n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "folder_path = r\"C:\\Users\\80710\\OneDrive - Imperial College London\\2025 engineering\\GNN molecules\\graph_pickles\"\n",
    "\n",
    "# Get all .pkl file paths in the folder\n",
    "pkl_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".pkl\")]\n",
    "\n",
    "# Load all graphs\n",
    "graph_list = []\n",
    "for file_path in pkl_files:\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        graph = pickle.load(file)  # Load each .pkl graph\n",
    "        graph_list.append(graph)  # Store in a list\n",
    "\n",
    "print(f\"Loaded {len(graph_list)} graphs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<networkx.classes.graph.Graph object at 0x000002B4FB32BB50>, <networkx.classes.graph.Graph object at 0x000002B4D49D12E0>, <networkx.classes.graph.Graph object at 0x000002B4F6E9C0A0>, <networkx.classes.graph.Graph object at 0x000002B4F76C1A60>, <networkx.classes.graph.Graph object at 0x000002B4F7B25AF0>, <networkx.classes.graph.Graph object at 0x000002B4F7B25A90>, <networkx.classes.graph.Graph object at 0x000002B4F7BC5D60>, <networkx.classes.graph.Graph object at 0x000002B4F7BE4580>, <networkx.classes.graph.Graph object at 0x000002B4F7C2CFD0>, <networkx.classes.graph.Graph object at 0x000002B4F7C2CEB0>, <networkx.classes.graph.Graph object at 0x000002B4F7C2CDC0>, <networkx.classes.graph.Graph object at 0x000002B4F7C2CC70>, <networkx.classes.graph.Graph object at 0x000002B4F7C2CBB0>, <networkx.classes.graph.Graph object at 0x000002B4F7C2C640>, <networkx.classes.graph.Graph object at 0x000002B4F7C2C130>, <networkx.classes.graph.Graph object at 0x000002B4F7CE32E0>, <networkx.classes.graph.Graph object at 0x000002B4F7CE30D0>, <networkx.classes.graph.Graph object at 0x000002B4F7CE3190>, <networkx.classes.graph.Graph object at 0x000002B4F7CE3250>, <networkx.classes.graph.Graph object at 0x000002B4FB40D2B0>]\n"
     ]
    }
   ],
   "source": [
    "print(graph_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 104], symbol=[48], rdkit_idx=[48], bond_index=[104], bde_pred=[104], bdfe_pred=[104], mol=<rdkit.Chem.rdchem.Mol object at 0x000002B4F7C88890>, num_nodes=48)\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "pyg_data_list = []\n",
    "for G in graph_list:\n",
    "    # Convert NetworkX Graph to PyTorch Geometric Data\n",
    "    data = from_networkx(G)\n",
    "    pyg_data_list.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 104], symbol=[48], rdkit_idx=[48], bond_index=[104], bde_pred=[104], bdfe_pred=[104], mol=<rdkit.Chem.rdchem.Mol object at 0x000002B4F7C88890>, num_nodes=48)\n"
     ]
    }
   ],
   "source": [
    "# 检查\n",
    "# Now 'pyg_data_list' is a list of PyG Data objects\n",
    "\n",
    "print(pyg_data_list[19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the environmental variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1023 environment rows\n",
      "   temperature  seawater  time  concentration  degradation_rate\n",
      "0         35.6         1    30             70          0.670914\n",
      "1         35.6         1    30             70          0.680071\n",
      "2         35.6         1    30             70          0.655230\n",
      "3         35.6         1    30             70          0.625193\n",
      "4         35.6         1    30             70          0.605853\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the environmental data from Excel\n",
    "env_file = r\"C:\\Users\\80710\\OneDrive - Imperial College London\\2025 engineering\\GNN molecules\\graph_pickles\\dataset02.xlsx\"\n",
    "env_df = pd.read_excel(env_file, engine='openpyxl')\n",
    "\n",
    "# Select only the relevant columns for the environment\n",
    "env_columns = [\"temperature\", \"seawater\", \"time\", \"concentration\", \"degradation_rate\"]\n",
    "\n",
    "# Ensure all columns exist in the dataset\n",
    "env_df = env_df[env_columns].copy()\n",
    "\n",
    "# Convert categorical \"seawater\" to numerical (if needed)\n",
    "env_df[\"seawater\"] = env_df[\"seawater\"].map({\"sea\": 1, \"art\": 0})  # Map \"sea\" → 1, \"art\" → 0\n",
    "\n",
    "# Drop rows with missing values\n",
    "env_df = env_df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Check if it matches the number of graphs\n",
    "print(f\"Loaded {len(env_df)} environment rows\")\n",
    "print(env_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "1023\n"
     ]
    }
   ],
   "source": [
    "print(len(pyg_data_list))\n",
    "print(len(env_df)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use environmental variables as Transformer Positional Encoding connect\n",
    "\n",
    "simply use nx graph is enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1  建立Build DataLoader\n",
    "PYG的Data对象代表图形，图形在节点和边缘的数量上有所不同。默认的DataLoader试图像张量一样堆叠它们，是不行滴。\n",
    " Custom Collate？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "Mgraph = pytorch_graphs[i]\n",
    "my_x = Mgraph.x\n",
    "\n",
    "print(len(my_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) First, create the base PyG graphs (without env, just x/edge_index/edge_attr)\n",
    "#    same code as before, but don't attach .env or .y\n",
    "#    we store them in base_graphs\n",
    "base_graphs = []\n",
    "\n",
    "for i, file_path in enumerate(pkl_files):\n",
    "    # your Nx -> PyG code, etc...\n",
    "    pyg_graph = Data(x=..., edge_index=..., edge_attr=...)\n",
    "    base_graphs.append(pyg_graph)\n",
    "\n",
    "print(\"Created\", len(base_graphs), \"graphs without environment data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 4 graphs without environment data.\n",
      "Created 80 graphs with environment + target info.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 2) Then replicate each base graph for each environment row\n",
    "expanded_graphs = []\n",
    "\n",
    "for i, g in enumerate(base_graphs):\n",
    "    for j, row in env_df.iterrows():\n",
    "        # Create a new Data object that merges the graph with this env row\n",
    "        env_feats = [\n",
    "            row[\"temperature\"],\n",
    "            row[\"seawater\"],\n",
    "            row[\"time\"],\n",
    "            row[\"concentration\"]\n",
    "        ]\n",
    "        y_value = row[\"degradation_rate\"]\n",
    "        \n",
    "        new_g = Data(\n",
    "            x=g.x,\n",
    "            edge_index=g.edge_index,\n",
    "            edge_attr=g.edge_attr,\n",
    "            env=torch.tensor(env_feats, dtype=torch.float),\n",
    "            y=torch.tensor([y_value], dtype=torch.float)\n",
    "        )\n",
    "        expanded_graphs.append(new_g)\n",
    "\n",
    "print(\"Created\", len(expanded_graphs), \"graphs with environment + target info.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 建立 env + molecules graph层 → 建立GNN\n",
    "由于PYG将多个图批量分为一个大图结构，因此我们需要data.batch来确保每个节点都会收到其相应图的正确环境嵌入\n",
    "1.PYG将多个图形组合在一起→来自不同图形的节点被连接\n",
    "2.data.batch tracks nodes属于哪个图。\n",
    "3.我们使用env_pos_emb[data.batch]添加每个节点的正确环境效果\n",
    "4.这确保每个节点都会获取其相应的环境编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class MolEnvGNN(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 node_in_dim,      # dimension of x (e.g. 1 if using a simple 0/1 feature)\n",
    "                 node_hidden_dim,  # hidden dimension for the GNN layers\n",
    "                 env_in_dim,       # dimension of environment input (4 in your case)\n",
    "                 env_hidden_dim,   # hidden dimension for environment MLP\n",
    "                 output_dim=1):\n",
    "        super(MolEnvGNN, self).__init__()\n",
    "        \n",
    "        # -- GNN layers --\n",
    "        self.conv1 = GCNConv(node_in_dim, node_hidden_dim)\n",
    "        self.conv2 = GCNConv(node_hidden_dim, node_hidden_dim)\n",
    "        \n",
    "        # -- Environment MLP --\n",
    "        self.env_mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(env_in_dim, env_hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(env_hidden_dim, env_hidden_dim),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # -- Final regressor --\n",
    "        self.lin = torch.nn.Linear(node_hidden_dim + env_hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, batch, env):\n",
    "        \"\"\"\n",
    "        x: Node features for all graphs in the batch\n",
    "        edge_index: Edge connectivity\n",
    "        batch: Assignment of each node to its graph in the batch\n",
    "        env: Environment features, shape [batch_size, env_in_dim]\n",
    "        \"\"\"\n",
    "        # 1) Node embedding via GNN\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = F.relu(h)\n",
    "        \n",
    "        # 2) Graph-level embedding\n",
    "        #    We pool node embeddings for each graph in the batch\n",
    "        gnn_emb = global_mean_pool(h, batch)  # shape = [batch_size, node_hidden_dim]\n",
    "        \n",
    "        # 3) Environment embedding\n",
    "        env_emb = self.env_mlp(env)           # shape = [batch_size, env_hidden_dim]\n",
    "        \n",
    "        # 4) Concatenate and predict\n",
    "        combined = torch.cat([gnn_emb, env_emb], dim=-1)\n",
    "        out = self.lin(combined)              # shape = [batch_size, 1]\n",
    "        return out.squeeze(-1)                # shape = [batch_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 MSE/RMSE/R2 检验 → 测试model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch_geometric\\data\\storage.py:452: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_attr', 'y', 'env', 'edge_index', 'x'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'GCNConv' received a tuple of node features as input while this layer does not support bipartite message passing. Please try other layers such as 'SAGEConv' or 'GraphConv' instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m y_true \u001b[38;5;241m=\u001b[39m batch_data\u001b[38;5;241m.\u001b[39my           \u001b[38;5;66;03m# shape [batch_size, 1] or [batch_size]\u001b[39;00m\n\u001b[0;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 33\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_feats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Flatten y_true if needed\u001b[39;00m\n\u001b[0;32m     35\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, y_true\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[25], line 37\u001b[0m, in \u001b[0;36mMolEnvGNN.forward\u001b[1;34m(self, x, edge_index, batch, env)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03mx: Node features for all graphs in the batch\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03medge_index: Edge connectivity\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03mbatch: Assignment of each node to its graph in the batch\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03menv: Environment features, shape [batch_size, env_in_dim]\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# 1) Node embedding via GNN\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(h)\n\u001b[0;32m     39\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(h, edge_index)\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:231\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, edge_index: Adj,\n\u001b[0;32m    228\u001b[0m             edge_weight: OptTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m--> 231\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m received a tuple \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof node features as input while this layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not support bipartite message passing. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    234\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease try other layers such as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAGEConv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    235\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGraphConv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize:\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, Tensor):\n",
      "\u001b[1;31mValueError\u001b[0m: 'GCNConv' received a tuple of node features as input while this layer does not support bipartite message passing. Please try other layers such as 'SAGEConv' or 'GraphConv' instead"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# 1) Create a DataLoader from expanded_graphs\n",
    "#    You can shuffle for random batching\n",
    "train_loader = DataLoader(expanded_graphs, batch_size=8, shuffle=True)\n",
    "\n",
    "# 2) Instantiate the model\n",
    "node_in_dim = 1      \n",
    "env_in_dim = 4       # temperature, seawater, time, concentration\n",
    "node_hidden_dim = 64\n",
    "env_hidden_dim = 32\n",
    "lr = 1e-3\n",
    "num_epochs = 20\n",
    "\n",
    "model = MolEnvGNN(node_in_dim, node_hidden_dim, env_in_dim, env_hidden_dim, output_dim=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.MSELoss()  # or L1Loss, etc.\n",
    "\n",
    "# 3) Training loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_data in train_loader:\n",
    "        # batch_data is a 'Data' object containing the batched graphs\n",
    "        # Access the fields:\n",
    "        x = batch_data.x                # All node features in the batch\n",
    "        edge_index = batch_data.edge_index\n",
    "        batch_idx = batch_data.batch    # Tells which nodes belong to which graph\n",
    "        env_feats = batch_data.env      # shape [batch_size, 4]\n",
    "        y_true = batch_data.y           # shape [batch_size, 1] or [batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x, edge_index, batch_idx, env_feats)\n",
    "        # Flatten y_true if needed\n",
    "        loss = criterion(y_pred, y_true.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'GCNConv' received a tuple of node features as input while this layer does not support bipartite message passing. Please try other layers such as 'SAGEConv' or 'GraphConv' instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Example: predict on 1 batch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     batch_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n\u001b[1;32m----> 5\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_pred)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTargets:\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[25], line 37\u001b[0m, in \u001b[0;36mMolEnvGNN.forward\u001b[1;34m(self, x, edge_index, batch, env)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03mx: Node features for all graphs in the batch\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03medge_index: Edge connectivity\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03mbatch: Assignment of each node to its graph in the batch\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03menv: Environment features, shape [batch_size, env_in_dim]\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# 1) Node embedding via GNN\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(h)\n\u001b[0;32m     39\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(h, edge_index)\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:231\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, edge_index: Adj,\n\u001b[0;32m    228\u001b[0m             edge_weight: OptTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m--> 231\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m received a tuple \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof node features as input while this layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not support bipartite message passing. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    234\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease try other layers such as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAGEConv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    235\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGraphConv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize:\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, Tensor):\n",
      "\u001b[1;31mValueError\u001b[0m: 'GCNConv' received a tuple of node features as input while this layer does not support bipartite message passing. Please try other layers such as 'SAGEConv' or 'GraphConv' instead"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Example: predict on 1 batch\n",
    "    batch_data = next(iter(train_loader))\n",
    "    y_pred = model(batch_data.x,\n",
    "                   batch_data.edge_index,\n",
    "                   batch_data.batch,\n",
    "                   batch_data.env)\n",
    "    print(\"Predictions:\", y_pred)\n",
    "    print(\"Targets:\", batch_data.y.view(-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Suppose your environment DataFrame is called `df_env`.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Suppose it has columns:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#  [\"temperature\", \"seawater\", \"time\", \"concentration\", \"degradation_rate\"]\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# and each row matches one molecule in `pytorch_graphs`.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 1. Create dataset\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m dataset \u001b[38;5;241m=\u001b[39m MoleculeEnvDataset(pyg_graphs\u001b[38;5;241m=\u001b[39mpytorch_graphs, env_df\u001b[38;5;241m=\u001b[39m\u001b[43mdf_env\u001b[49m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 2. Create dataloader\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_env' is not defined"
     ]
    }
   ],
   "source": [
    "# Suppose your environment DataFrame is called `df_env`.\n",
    "# Suppose it has columns:\n",
    "#  [\"temperature\", \"seawater\", \"time\", \"concentration\", \"degradation_rate\"]\n",
    "# and each row matches one molecule in `pytorch_graphs`.\n",
    "\n",
    "# 1. Create dataset\n",
    "dataset = MoleculeEnvDataset(pyg_graphs=pytorch_graphs, env_df=df_env)\n",
    "\n",
    "# 2. Create dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=my_collate)\n",
    "\n",
    "# 3. Initialize model\n",
    "num_node_features = 1  # if your x is [N,1], e.g. one-hot for C vs H\n",
    "env_input_dim = 4       # [temperature, concentration, time, maybe 'seawater']\n",
    "model = SimpleGraphModel(num_node_features=num_node_features,\n",
    "                         env_input_dim=env_input_dim,\n",
    "                         hidden_dim=128,\n",
    "                         output_dim=1)\n",
    "\n",
    "# 4. Train\n",
    "train_model(model, dataloader, device='cpu', epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_model(\u001b[43mmodel\u001b[49m, dataloader, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "train_model(model, dataloader, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. fixed code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(pytorch_graphs))   # Should be 20\n",
    "print(len(env_df))           # Must also be 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class MoleculeEnvDataset(Dataset):\n",
    "    def __init__(self, pyg_graphs, env_df):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pyg_graphs: list of PyG Data objects (molecules)\n",
    "            env_df: pandas DataFrame with environmental conditions & target\n",
    "        \"\"\"\n",
    "        self.pyg_graphs = pyg_graphs\n",
    "        self.env_df = env_df\n",
    "        \n",
    "        # 1. Expand molecule data to match env_df length\n",
    "        self.graphs_expanded = [pyg_graphs[i % len(pyg_graphs)] for i in range(len(env_df))]\n",
    "\n",
    "        # 2. Extract environmental conditions\n",
    "        self.env_features = torch.tensor(\n",
    "            self.env_df[[\"temperature\", \"seawater\", \"time\", \"concentration\"]].values, dtype=torch.float\n",
    "        )\n",
    "\n",
    "        # 3. Extract degradation rate as target\n",
    "        self.targets = torch.tensor(self.env_df[\"degradation_rate\"].values, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.env_df)  # Matches number of experimental conditions\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.graphs_expanded[idx]  # Get corresponding molecule\n",
    "        env_features = self.env_features[idx]  # Get environmental variables\n",
    "        target = self.targets[idx]  # Get degradation rate\n",
    "\n",
    "        return graph, env_features, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[42, 1], edge_index=[2, 44], edge_attr=[44, 2])\n",
      "tensor([35.6000,  1.0000, 30.0000, 70.0000])\n",
      "tensor(0.6709)\n"
     ]
    }
   ],
   "source": [
    "# 创建 Dataset\n",
    "dataset = MoleculeEnvDataset(pyg_graphs=pytorch_graphs, env_df=env_df)\n",
    "\n",
    "# 创建 DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# 检查 Dataset 结构\n",
    "graph, env_features, target = dataset[0]\n",
    "print(graph)  # Should be a PyG Data object\n",
    "print(env_features)  # Should be a tensor with 4 environmental variables\n",
    "print(target)  # Should be a single float value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SimpleGraphModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m num_node_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# 节点特征\u001b[39;00m\n\u001b[0;32m      3\u001b[0m env_input_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m  \u001b[38;5;66;03m# 环境变量：[温度，海水类型，时间，浓度]\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleGraphModel\u001b[49m(num_node_features\u001b[38;5;241m=\u001b[39mnum_node_features,\n\u001b[0;32m      5\u001b[0m                          env_input_dim\u001b[38;5;241m=\u001b[39menv_input_dim,\n\u001b[0;32m      6\u001b[0m                          hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[0;32m      7\u001b[0m                          output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[0;32m     10\u001b[0m train_model(model, dataloader, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SimpleGraphModel' is not defined"
     ]
    }
   ],
   "source": [
    "# 假设你的 GNN 结构如下：\n",
    "num_node_features = 1  # 节点特征\n",
    "env_input_dim = 4  # 环境变量：[温度，海水类型，时间，浓度]\n",
    "model = SimpleGraphModel(num_node_features=num_node_features,\n",
    "                         env_input_dim=env_input_dim,\n",
    "                         hidden_dim=128,\n",
    "                         output_dim=1)\n",
    "\n",
    "# 训练模型\n",
    "train_model(model, dataloader, device='cpu', epochs=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    temperature  seawater  time  concentration\n",
      "0          35.6         0    30             70\n",
      "1          35.6         0    30            700\n",
      "2          35.6         0    60             70\n",
      "3          35.6         0    60            700\n",
      "4          35.6         1    30             70\n",
      "5          35.6         1    30            700\n",
      "6          35.6         1    60             70\n",
      "7          35.6         1    60            700\n",
      "8          86.0         0    30             70\n",
      "9          86.0         0    30            700\n",
      "10         86.0         0    60             70\n",
      "11         86.0         0    60            700\n",
      "12         86.0         1    30             70\n",
      "13         86.0         1    30            700\n",
      "14         86.0         1    60             70\n",
      "15         86.0         1    60            700\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# 所有环境变量的可能取值\n",
    "temperature_values = [35.6, 86.0]\n",
    "seawater_values = [0, 1]  # 这里用 0 (sea), 1 (art) 代替字符串\n",
    "time_values = [30, 60]\n",
    "concentration_values = [70, 700]\n",
    "\n",
    "# **创建所有组合（16个环境变量组合）**\n",
    "env_conditions = list(itertools.product(\n",
    "    temperature_values, seawater_values, time_values, concentration_values\n",
    "))\n",
    "\n",
    "# 转为 Pandas DataFrame，便于查看\n",
    "env_df = pd.DataFrame(env_conditions, columns=[\"temperature\", \"seawater\", \"time\", \"concentration\"])\n",
    "print(env_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset, Data, Batch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class MoleculeEnvDataset(Dataset):\n",
    "    def __init__(self, pyg_graphs, env_df):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pyg_graphs: list of 20 PyG 分子图\n",
    "            env_df: 16 组环境变量\n",
    "        \"\"\"\n",
    "        self.pyg_graphs = pyg_graphs  # 20个分子\n",
    "        self.env_df = env_df\n",
    "\n",
    "        # **创建 (20 × 16) 组实验数据**\n",
    "        self.dataset = [\n",
    "            (self.pyg_graphs[i % len(self.pyg_graphs)], torch.tensor(env, dtype=torch.float))\n",
    "            for i in range(len(self.pyg_graphs) * len(self.env_df))\n",
    "            for env in self.env_df.values\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)  # 320 组数据\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph, env_features = self.dataset[idx]\n",
    "        return graph, env_features\n",
    "\n",
    "# **创建 Dataset**\n",
    "dataset = MoleculeEnvDataset(pyg_graphs=pytorch_graphs, env_df=env_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeEnvDataset(Dataset):\n",
    "    def __init__(self, pyg_graphs, env_df, target_values):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pyg_graphs: list of 20 PyG 分子图\n",
    "            env_df: 16 组环境变量\n",
    "            target_values: 320 组目标降解率 (每个分子在不同环境下的实验结果)\n",
    "        \"\"\"\n",
    "        self.pyg_graphs = pyg_graphs\n",
    "        self.env_df = env_df\n",
    "        self.target_values = target_values  # 目标值 (320个)\n",
    "\n",
    "        # **创建 (20 × 16) 组实验数据**\n",
    "        self.dataset = [\n",
    "            (self.pyg_graphs[i % len(self.pyg_graphs)],  # Graph\n",
    "             torch.tensor(env, dtype=torch.float),       # 环境变量\n",
    "             torch.tensor(self.target_values[i], dtype=torch.float))  # 目标值\n",
    "            for i in range(len(self.pyg_graphs) * len(self.env_df))\n",
    "            for env in self.env_df.values\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)  # 320 组数据\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph, env_features, target = self.dataset[idx]\n",
    "        return graph, env_features, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mmy_collate)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# **检查 DataLoader**\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m graphs_batch, env_features_batch, targets_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(graphs_batch)  \u001b[38;5;66;03m# PyG DataBatch\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(env_features_batch\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# (batch_size, 4)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m, in \u001b[0;36mmy_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmy_collate\u001b[39m(batch):\n\u001b[1;32m----> 2\u001b[0m     graphs, env_features, targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)  \u001b[38;5;66;03m# 拆分 Graph, 环境变量, 目标值\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     graphs_batch \u001b[38;5;241m=\u001b[39m Batch\u001b[38;5;241m.\u001b[39mfrom_data_list(graphs)  \u001b[38;5;66;03m# PyG 批量处理\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     env_features_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(env_features)  \u001b[38;5;66;03m# 转 Tensor\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "def my_collate(batch):\n",
    "    graphs, env_features, targets = zip(*batch)  # 拆分 Graph, 环境变量, 目标值\n",
    "    graphs_batch = Batch.from_data_list(graphs)  # PyG 批量处理\n",
    "    env_features_batch = torch.stack(env_features)  # 转 Tensor\n",
    "    targets_batch = torch.stack(targets)  # 转 Tensor\n",
    "    return graphs_batch, env_features_batch, targets_batch\n",
    "\n",
    "# **创建 DataLoader**\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=my_collate)\n",
    "\n",
    "# **检查 DataLoader**\n",
    "graphs_batch, env_features_batch, targets_batch = next(iter(dataloader))\n",
    "print(graphs_batch)  # PyG DataBatch\n",
    "print(env_features_batch.shape)  # (batch_size, 4)\n",
    "print(targets_batch.shape)  # (batch_size,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 11\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m SimpleGraphModel(num_node_features\u001b[38;5;241m=\u001b[39mnum_node_features,\n\u001b[0;32m      6\u001b[0m                          env_input_dim\u001b[38;5;241m=\u001b[39menv_input_dim,\n\u001b[0;32m      7\u001b[0m                          hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[0;32m      8\u001b[0m                          output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# **训练模型**\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, device, epochs)\u001b[0m\n\u001b[0;32m     10\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     11\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m graphs_batch, envs_batch, targets_batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     14\u001b[0m     graphs_batch \u001b[38;5;241m=\u001b[39m graphs_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m     envs_batch \u001b[38;5;241m=\u001b[39m envs_batch\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m, in \u001b[0;36mmy_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmy_collate\u001b[39m(batch):\n\u001b[1;32m----> 2\u001b[0m     graphs, env_features, targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)  \u001b[38;5;66;03m# 拆分 Graph, 环境变量, 目标值\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     graphs_batch \u001b[38;5;241m=\u001b[39m Batch\u001b[38;5;241m.\u001b[39mfrom_data_list(graphs)  \u001b[38;5;66;03m# PyG 批量处理\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     env_features_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(env_features)  \u001b[38;5;66;03m# 转 Tensor\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "# 假设 GNN 结构如下：\n",
    "num_node_features = 1  # 节点特征\n",
    "env_input_dim = 4  # 环境变量：[温度，海水类型，时间，浓度]\n",
    "\n",
    "model = SimpleGraphModel(num_node_features=num_node_features,\n",
    "                         env_input_dim=env_input_dim,\n",
    "                         hidden_dim=128,\n",
    "                         output_dim=1)\n",
    "\n",
    "# **训练模型**\n",
    "train_model(model, dataloader, device='cpu', epochs=20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alfabet-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
