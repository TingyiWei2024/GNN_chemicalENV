{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA \n",
    "1. input molecules graph data √\n",
    "2. input correct env variable √  - btw: art is what seawater?\n",
    "3. connect these data ×\n",
    "只匹配环境变量 20×16 = 320 和 1023对不上（这个因为同一环境条件下对一个分子不止做了一次实验，明天再研究下能怎么匹配），我明天再改下，\n",
    "还是得从表格取env_df\n",
    "卡住"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load molecules graph datas from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 graphs\n"
     ]
    }
   ],
   "source": [
    "## Load the molecular data (.pkl) for molecules with Targeted BDE & BDFE \n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "folder_path = r\"C:\\Users\\80710\\OneDrive - Imperial College London\\2025 engineering\\GNN molecules\\graph_pickles\"\n",
    "\n",
    "# Get all .pkl file paths in the folder\n",
    "pkl_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".pkl\")]\n",
    "\n",
    "# Load all graphs\n",
    "graph_list = []\n",
    "for file_path in pkl_files:\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        graph = pickle.load(file)  # Load each .pkl graph\n",
    "        graph_list.append(graph)  # Store in a list\n",
    "\n",
    "print(f\"Loaded {len(graph_list)} graphs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>rdkit_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>C</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>C</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>C</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_41</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_49</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_47</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_33</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_32</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_30</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_40</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_28</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_46</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_59</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_37</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_61</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_56</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_27</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_44</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_62</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_52</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_36</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_23</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol  rdkit_idx\n",
       "0         C        0.0\n",
       "1         C        1.0\n",
       "2         C        2.0\n",
       "3         C        3.0\n",
       "4         C        4.0\n",
       "5         C        5.0\n",
       "6         C        6.0\n",
       "7         C        7.0\n",
       "8         C        8.0\n",
       "9         C        9.0\n",
       "10        C       10.0\n",
       "11        C       11.0\n",
       "12        C       12.0\n",
       "13        C       13.0\n",
       "14        C       14.0\n",
       "15        C       15.0\n",
       "16        C       16.0\n",
       "17        C       17.0\n",
       "18        C       18.0\n",
       "19        C       19.0\n",
       "20        C       20.0\n",
       "21        C       21.0\n",
       "22        C       22.0\n",
       "H_41      H        NaN\n",
       "H_49      H        NaN\n",
       "H_47      H        NaN\n",
       "H_33      H        NaN\n",
       "H_32      H        NaN\n",
       "H_30      H        NaN\n",
       "H_40      H        NaN\n",
       "H_28      H        NaN\n",
       "H_46      H        NaN\n",
       "H_59      H        NaN\n",
       "H_37      H        NaN\n",
       "H_61      H        NaN\n",
       "H_56      H        NaN\n",
       "H_27      H        NaN\n",
       "H_44      H        NaN\n",
       "H_62      H        NaN\n",
       "H_52      H        NaN\n",
       "H_36      H        NaN\n",
       "H_23      H        NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>bond_index</th>\n",
       "      <th>bde_pred</th>\n",
       "      <th>bdfe_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.382645</td>\n",
       "      <td>75.711845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>H_23</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.077171</td>\n",
       "      <td>91.049126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.872452</td>\n",
       "      <td>71.412849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>H_27</td>\n",
       "      <td>29.0</td>\n",
       "      <td>97.163109</td>\n",
       "      <td>87.689636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.041306</td>\n",
       "      <td>70.000282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>H_28</td>\n",
       "      <td>30.0</td>\n",
       "      <td>95.392189</td>\n",
       "      <td>86.257263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>83.115479</td>\n",
       "      <td>66.995277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>H_30</td>\n",
       "      <td>32.0</td>\n",
       "      <td>94.518471</td>\n",
       "      <td>84.748619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>H_32</td>\n",
       "      <td>34.0</td>\n",
       "      <td>93.767830</td>\n",
       "      <td>84.237808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>86.171143</td>\n",
       "      <td>71.943573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>H_33</td>\n",
       "      <td>35.0</td>\n",
       "      <td>93.715744</td>\n",
       "      <td>84.072701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>H_36</td>\n",
       "      <td>38.0</td>\n",
       "      <td>98.747513</td>\n",
       "      <td>89.695892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>H_37</td>\n",
       "      <td>39.0</td>\n",
       "      <td>95.855804</td>\n",
       "      <td>86.941345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>H_40</td>\n",
       "      <td>42.0</td>\n",
       "      <td>94.971001</td>\n",
       "      <td>85.988342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>H_41</td>\n",
       "      <td>43.0</td>\n",
       "      <td>86.859306</td>\n",
       "      <td>75.766228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>79.460541</td>\n",
       "      <td>64.253868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11</td>\n",
       "      <td>H_44</td>\n",
       "      <td>46.0</td>\n",
       "      <td>97.184883</td>\n",
       "      <td>88.282661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12</td>\n",
       "      <td>H_46</td>\n",
       "      <td>48.0</td>\n",
       "      <td>95.408730</td>\n",
       "      <td>86.714386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>H_47</td>\n",
       "      <td>49.0</td>\n",
       "      <td>92.920937</td>\n",
       "      <td>84.154495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>14</td>\n",
       "      <td>H_49</td>\n",
       "      <td>51.0</td>\n",
       "      <td>89.283218</td>\n",
       "      <td>79.903214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>15.0</td>\n",
       "      <td>82.408630</td>\n",
       "      <td>67.338509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16</td>\n",
       "      <td>H_52</td>\n",
       "      <td>54.0</td>\n",
       "      <td>98.126961</td>\n",
       "      <td>89.117233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>18</td>\n",
       "      <td>H_56</td>\n",
       "      <td>58.0</td>\n",
       "      <td>96.827797</td>\n",
       "      <td>87.840210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>19</td>\n",
       "      <td>H_59</td>\n",
       "      <td>61.0</td>\n",
       "      <td>95.608147</td>\n",
       "      <td>86.592361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>20</td>\n",
       "      <td>H_61</td>\n",
       "      <td>63.0</td>\n",
       "      <td>96.082130</td>\n",
       "      <td>87.054794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>21.0</td>\n",
       "      <td>79.644073</td>\n",
       "      <td>64.361122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>22</td>\n",
       "      <td>H_62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>97.762428</td>\n",
       "      <td>88.862091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source target  bond_index    bde_pred  bdfe_pred\n",
       "0        0      1         0.0   89.382645  75.711845\n",
       "1        0   H_23        25.0  100.077171  91.049126\n",
       "2        1      2         1.0   85.872452  71.412849\n",
       "3        1   H_27        29.0   97.163109  87.689636\n",
       "4        2      3         2.0   85.041306  70.000282\n",
       "5        2   H_28        30.0   95.392189  86.257263\n",
       "6        3      4         3.0   83.115479  66.995277\n",
       "7        3   H_30        32.0   94.518471  84.748619\n",
       "8        4      5         NaN         NaN        NaN\n",
       "9        4     10         NaN         NaN        NaN\n",
       "10       4   H_32        34.0   93.767830  84.237808\n",
       "11       5      6         5.0   86.171143  71.943573\n",
       "12       5      7         NaN         NaN        NaN\n",
       "13       5   H_33        35.0   93.715744  84.072701\n",
       "14       6   H_36        38.0   98.747513  89.695892\n",
       "15       7      8         NaN         NaN        NaN\n",
       "16       7   H_37        39.0   95.855804  86.941345\n",
       "17       8      9         NaN         NaN        NaN\n",
       "18       8   H_40        42.0   94.971001  85.988342\n",
       "19       9     10         NaN         NaN        NaN\n",
       "20       9     21         NaN         NaN        NaN\n",
       "21       9   H_41        43.0   86.859306  75.766228\n",
       "22      10     11        10.0   79.460541  64.253868\n",
       "23      10     12         NaN         NaN        NaN\n",
       "24      11   H_44        46.0   97.184883  88.282661\n",
       "25      12     13         NaN         NaN        NaN\n",
       "26      12   H_46        48.0   95.408730  86.714386\n",
       "27      13     14         NaN         NaN        NaN\n",
       "28      13   H_47        49.0   92.920937  84.154495\n",
       "29      14     15         NaN         NaN        NaN\n",
       "30      14     21         NaN         NaN        NaN\n",
       "31      14   H_49        51.0   89.283218  79.903214\n",
       "32      15     16        15.0   82.408630  67.338509\n",
       "33      15     17         NaN         NaN        NaN\n",
       "34      15     18         NaN         NaN        NaN\n",
       "35      16   H_52        54.0   98.126961  89.117233\n",
       "36      18     19         NaN         NaN        NaN\n",
       "37      18   H_56        58.0   96.827797  87.840210\n",
       "38      19     20         NaN         NaN        NaN\n",
       "39      19   H_59        61.0   95.608147  86.592361\n",
       "40      20     21         NaN         NaN        NaN\n",
       "41      20   H_61        63.0   96.082130  87.054794\n",
       "42      21     22        21.0   79.644073  64.361122\n",
       "43      22   H_62        64.0   97.762428  88.862091"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 检查\n",
    "import pandas as pd\n",
    "\n",
    "# Select the first graph for visualization\n",
    "nx_graph = graph_list[0]\n",
    "\n",
    "# Convert node data to DataFrame\n",
    "node_data = pd.DataFrame.from_dict(dict(nx_graph.nodes(data=True)), orient=\"index\")\n",
    "\n",
    "# Convert edge data to DataFrame\n",
    "edge_data = pd.DataFrame.from_records([(u, v, d) for u, v, d in nx_graph.edges(data=True)], \n",
    "                                      columns=[\"source\", \"target\", \"attributes\"])\n",
    "\n",
    "# Expand edge attributes\n",
    "if not edge_data.empty and isinstance(edge_data.iloc[0][\"attributes\"], dict):\n",
    "    attr_df = edge_data[\"attributes\"].apply(pd.Series)  # Convert dict to columns\n",
    "    edge_data = pd.concat([edge_data.drop(columns=[\"attributes\"]), attr_df], axis=1)\n",
    "\n",
    "# Display DataFrames\n",
    "from IPython.display import display\n",
    "display(node_data)\n",
    "display(edge_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking: 为什么rdix里H对应的都是NAN 我们转化时用的是H-H 单H 键不需要 再进入rdix编号\n",
    "\n",
    "备注：os.listdir... 列出文件夹中文件名称，迭代获取，保留.pkl,output list\n",
    "     \"rb\"对口pkl二进制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Graph 1: 42 nodes, 44 edges\n",
      "Converted Graph 2: 43 nodes, 45 edges\n",
      "Converted Graph 3: 52 nodes, 56 edges\n",
      "Converted Graph 4: 54 nodes, 58 edges\n",
      "Converted Graph 5: 56 nodes, 60 edges\n",
      "Converted Graph 6: 56 nodes, 60 edges\n",
      "Converted Graph 7: 58 nodes, 62 edges\n",
      "Converted Graph 8: 58 nodes, 62 edges\n",
      "Converted Graph 9: 60 nodes, 64 edges\n",
      "Converted Graph 10: 60 nodes, 64 edges\n",
      "Converted Graph 11: 62 nodes, 66 edges\n",
      "Converted Graph 12: 62 nodes, 66 edges\n",
      "Converted Graph 13: 46 nodes, 48 edges\n",
      "Converted Graph 14: 48 nodes, 50 edges\n",
      "Converted Graph 15: 52 nodes, 54 edges\n",
      "Converted Graph 16: 52 nodes, 54 edges\n",
      "Converted Graph 17: 53 nodes, 55 edges\n",
      "Converted Graph 18: 53 nodes, 55 edges\n",
      "Converted Graph 19: 48 nodes, 52 edges\n",
      "Converted Graph 20: 48 nodes, 52 edges\n",
      "\n",
      " Total converted graphs: 20\n"
     ]
    }
   ],
   "source": [
    "## Convert Graphs to PyTorch Geometric Format for GNN model\n",
    "# 方便训练和GNN计算，转化为PyG\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "\n",
    "# Path to dataset folder (Update this)\n",
    "folder_path = r\"C:\\Users\\80710\\OneDrive - Imperial College London\\2025 engineering\\GNN molecules\\graph_pickles\"\n",
    "\n",
    "# Get all .pkl file paths\n",
    "pkl_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".pkl\")]\n",
    "\n",
    "# List to store PyTorch Geometric graphs\n",
    "pytorch_graphs = []\n",
    "\n",
    "# **Function to handle missing hydrogen atom labels**\n",
    "def clean_node_labels(node_data):\n",
    "    \"\"\"Replace NaN hydrogen labels with unique identifiers.\"\"\"\n",
    "    return {node: idx if not pd.isna(node) else f\"H_{idx}\" for idx, node in enumerate(node_data)}\n",
    "\n",
    "# 分别提取节点和边的数据重构graph\n",
    "# **Loop through each .pkl file and convert to PyG format**\n",
    "for i, file_path in enumerate(pkl_files):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        nx_graph = pickle.load(file)  # Load NetworkX graph\n",
    "\n",
    "        if isinstance(nx_graph, nx.Graph):\n",
    "            # **Relabel nodes to avoid NaN values**\n",
    "            mapping = clean_node_labels(nx_graph.nodes())\n",
    "            nx_graph = nx.relabel_nodes(nx_graph, mapping)\n",
    "\n",
    "            # **Convert Edges to PyG format (edge_index)**\n",
    "            edge_index = torch.tensor(list(nx_graph.edges()), dtype=torch.long).T\n",
    "            if edge_index.numel() == 0:  # Handle cases with no edges\n",
    "                edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "            # **Extract Node Features (Use Atomic Symbols)**\n",
    "            first_node = next(iter(nx_graph.nodes), None)\n",
    "            if first_node is not None and \"symbol\" in nx_graph.nodes[first_node]:\n",
    "                node_features = torch.tensor(\n",
    "                    [[1 if nx_graph.nodes[n][\"symbol\"] == \"C\" else 0] for n in nx_graph.nodes()],\n",
    "                    dtype=torch.float\n",
    "                )  # One-hot encoding Carbon (C) vs Hydrogen (H)\n",
    "            else:\n",
    "                node_features = torch.zeros((len(nx_graph.nodes()), 1), dtype=torch.float)  # Default: 1D zero feature\n",
    "\n",
    "            # **Extract Edge Features (BDE, BDFE) - Handle NoneType**\n",
    "            edge_features_list = []\n",
    "            for u, v in nx_graph.edges():\n",
    "                bde = nx_graph[u][v].get(\"bde_pred\", 0.0)  # Replace None with 0.0\n",
    "                bdfe = nx_graph[u][v].get(\"bdfe_pred\", 0.0)  # Replace None with 0.0\n",
    "                edge_features_list.append([bde if bde is not None else 0.0, bdfe if bdfe is not None else 0.0])\n",
    "\n",
    "            edge_features = torch.tensor(edge_features_list, dtype=torch.float) if edge_features_list else None\n",
    "\n",
    "            # **Create PyG Graph**\n",
    "            pyg_graph = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "\n",
    "            # **Store Processed Graph**\n",
    "            pytorch_graphs.append(pyg_graph)\n",
    "            print(f\"Converted Graph {i+1}: {len(nx_graph.nodes)} nodes, {len(nx_graph.edges)} edges\")\n",
    "\n",
    "print(f\"\\n Total converted graphs: {len(pytorch_graphs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[42, 1], edge_index=[2, 44], edge_attr=[44, 2])\n"
     ]
    }
   ],
   "source": [
    "print(pytorch_graphs[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the environmental variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1023 environment rows\n",
      "   temperature  seawater  time  concentration  degradation_rate\n",
      "0         35.6         1    30             70          0.670914\n",
      "1         35.6         1    30             70          0.680071\n",
      "2         35.6         1    30             70          0.655230\n",
      "3         35.6         1    30             70          0.625193\n",
      "4         35.6         1    30             70          0.605853\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the environmental data from Excel\n",
    "env_file = r\"C:\\Users\\80710\\OneDrive - Imperial College London\\2025 engineering\\GNN molecules\\graph_pickles\\dataset02.xlsx\"\n",
    "env_df = pd.read_excel(env_file, engine='openpyxl')\n",
    "\n",
    "# Select only the relevant columns for the environment\n",
    "env_columns = [\"temperature\", \"seawater\", \"time\", \"concentration\", \"degradation_rate\"]\n",
    "\n",
    "# Ensure all columns exist in the dataset\n",
    "env_df = env_df[env_columns].copy()\n",
    "\n",
    "# Convert categorical \"seawater\" to numerical (if needed)\n",
    "env_df[\"seawater\"] = env_df[\"seawater\"].map({\"sea\": 1, \"art\": 0})  # Map \"sea\" → 1, \"art\" → 0\n",
    "\n",
    "# Drop rows with missing values\n",
    "env_df = env_df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Check if it matches the number of graphs\n",
    "print(f\"Loaded {len(env_df)} environment rows\")\n",
    "print(env_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "1023\n"
     ]
    }
   ],
   "source": [
    "print(len(pytorch_graphs))  # Should be 20\n",
    "print(len(env_df))          # Should also be 20\n",
    "\n",
    "# If they don’t match, fix by truncating or aligning:\n",
    "if len(env_df) > len(pytorch_graphs):\n",
    "    env_df = env_df.iloc[:len(pytorch_graphs)].reset_index(drop=True)\n",
    "elif len(env_df) < len(pytorch_graphs):\n",
    "    print(\"Warning: Not enough environment rows, some graphs will be missing data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use environmental variables as Transformer Positional Encoding connect\n",
    "\n",
    "simply use nx graph is enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MoleculeEnvDataset(Dataset):\n",
    "    def __init__(self, pyg_graphs, env_df):\n",
    "        \"\"\"\n",
    "        pyg_graphs: list of PyG Data objects\n",
    "        env_df: a pd.DataFrame with columns [\"temperature\", \"seawater\", \"time\", \"concentration\"], \n",
    "                or however you store your environment data.\n",
    "        \"\"\"\n",
    "        self.pyg_graphs = pyg_graphs\n",
    "        self.env_df = env_df  # DataFrame with shape [num_graphs, num_env_features]\n",
    "        \n",
    "        # Make sure lengths match\n",
    "        assert len(self.pyg_graphs) == len(self.env_df), \\\n",
    "            \"Number of graphs and env rows must match.\"\n",
    "        \n",
    "        # Pre-process environment features into numeric tensors\n",
    "        # E.g., one-hot encode 'seawater' if it's categorical, etc.\n",
    "        self.env_tensors = self.preprocess_env_features(self.env_df)\n",
    "\n",
    "    def preprocess_env_features(self, df):\n",
    "        \"\"\"\n",
    "        Convert 'sea'/'art' to 0 or 1, \n",
    "        or do a small one-hot if you prefer. \n",
    "        Also handle numeric columns. \n",
    "        Return a list of environment torch tensors.\n",
    "        \"\"\"\n",
    "        env_tensors = []\n",
    "        \n",
    "        # Example: map sea -> 1, art -> 0\n",
    "        sea_map = {'sea': 1.0, 'art': 0.0}\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            temperature = row[\"temperature\"]       # float\n",
    "            is_sea = sea_map.get(row[\"seawater\"], 0.0)  # float\n",
    "            time_val = row[\"time\"]                # float\n",
    "            concentration = row[\"concentration\"]  # float\n",
    "            \n",
    "            # Build environment feature vector [T, sea/0-1, time, concentration]\n",
    "            env_vec = torch.tensor([temperature, is_sea, time_val, concentration], dtype=torch.float)\n",
    "            env_tensors.append(env_vec)\n",
    "        \n",
    "        return env_tensors\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pyg_graphs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return a (graph, environment_vector) tuple for each sample.\"\"\"\n",
    "        graph = self.pyg_graphs[idx]\n",
    "        env_vec = self.env_tensors[idx]\n",
    "        return graph, env_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Number of graphs and env rows must match.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Suppose 'df_env' is your DataFrame loaded from dataset02.xlsx\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# with columns [temperature, seawater, time, concentration] in the right order\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mMoleculeEnvDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpytorch_graphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_env\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 16\u001b[0m, in \u001b[0;36mMoleculeEnvDataset.__init__\u001b[1;34m(self, pyg_graphs, env_df)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv_df \u001b[38;5;241m=\u001b[39m env_df  \u001b[38;5;66;03m# DataFrame with shape [num_graphs, num_env_features]\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Make sure lengths match\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpyg_graphs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv_df), \\\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of graphs and env rows must match.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Pre-process environment features into numeric tensors\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# E.g., one-hot encode 'seawater' if it's categorical, etc.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv_tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_env_features(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv_df)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Number of graphs and env rows must match."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Suppose 'df_env' is your DataFrame loaded from dataset02.xlsx\n",
    "# with columns [temperature, seawater, time, concentration] in the right order\n",
    "\n",
    "dataset = MoleculeEnvDataset(pytorch_graphs, df_env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1  建立Build DataLoader\n",
    "PYG的Data对象代表图形，图形在节点和边缘的数量上有所不同。默认的DataLoader试图像张量一样堆叠它们，是不行滴。\n",
    " Custom Collate？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\"\n",
    "    batch is a list of tuples: (pyg_graph, env_features, target).\n",
    "    We'll combine them into:\n",
    "      - DataBatch of graphs\n",
    "      - Stacked env_features\n",
    "      - Stacked targets\n",
    "    \"\"\"\n",
    "    graphs, envs, targets = zip(*batch)  # Unzip\n",
    "    \n",
    "    # 1) Batch the PyG graphs\n",
    "    graphs_batch = Batch.from_data_list(graphs)\n",
    "    \n",
    "    # 2) Stack env features\n",
    "    envs_batch = torch.stack(envs, dim=0)  # shape [batch_size, env_dim]\n",
    "    \n",
    "    # 3) Stack targets\n",
    "    targets_batch = torch.stack(targets, dim=0)  # shape [batch_size]\n",
    "    \n",
    "    return graphs_batch, envs_batch, targets_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 建立 env + molecules graph层 → 建立GNN\n",
    "由于PYG将多个图批量分为一个大图结构，因此我们需要data.batch来确保每个节点都会收到其相应图的正确环境嵌入\n",
    "1.PYG将多个图形组合在一起→来自不同图形的节点被连接\n",
    "2.data.batch tracks nodes属于哪个图。\n",
    "3.我们使用env_pos_emb[data.batch]添加每个节点的正确环境效果\n",
    "4.这确保每个节点都会获取其相应的环境编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EnvEmbeddingMLP(nn.Module):\n",
    "    def __init__(self, env_dim=4, model_dim=128, hidden_dim=64):\n",
    "        \"\"\"\n",
    "        env_dim: number of raw environment features\n",
    "        model_dim: dimension of the final embedding to match your Transformer\n",
    "        hidden_dim: dimension of the hidden layer in MLP\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(env_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, model_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, env_vector):\n",
    "        \"\"\"\n",
    "        env_vector: (batch_size, env_dim) or (env_dim,) if unbatched\n",
    "        return: (batch_size, model_dim)\n",
    "        \"\"\"\n",
    "        return self.mlp(env_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphTransformerModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 node_feat_dim=1,      # e.g. your PyG node feature dimension\n",
    "                 model_dim=128,\n",
    "                 num_heads=4,\n",
    "                 num_layers=3,\n",
    "                 env_dim=4,\n",
    "                 hidden_env=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Simple projection of node features up to model_dim\n",
    "        self.node_proj = nn.Linear(node_feat_dim, model_dim)\n",
    "        \n",
    "        # MLP to produce environment-based embedding\n",
    "        self.env_embed = EnvEmbeddingMLP(env_dim=env_dim, \n",
    "                                         model_dim=model_dim,\n",
    "                                         hidden_dim=hidden_env)\n",
    "        \n",
    "        # Define a standard Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim, \n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=256, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer, \n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        # Output layer (example: regression for some property)\n",
    "        self.out_layer = nn.Linear(model_dim, 1)\n",
    "        \n",
    "    def forward(self, graph_data, env_vector):\n",
    "        \"\"\"\n",
    "        graph_data: a PyG Data object with:\n",
    "            - x: node features shape [num_nodes, node_feat_dim]\n",
    "        env_vector: shape [env_dim]\n",
    "        \n",
    "        Return: a single scalar or a node-level output, depending on design.\n",
    "        \"\"\"\n",
    "        \n",
    "        x = graph_data.x  # [num_nodes, node_feat_dim]\n",
    "        \n",
    "        # 1) Project node features to model_dim\n",
    "        x = self.node_proj(x)  # [num_nodes, model_dim]\n",
    "        \n",
    "        # 2) Get environment embedding\n",
    "        #    shape [model_dim] or [1, model_dim]\n",
    "        env_emb = self.env_embed(env_vector.unsqueeze(0))  # -> [1, model_dim]\n",
    "        \n",
    "        # 3) Broadcast and add to every node\n",
    "        #    if x has shape [N, model_dim], we want env_emb repeated N times\n",
    "        x = x + env_emb  # Broadcasting: [N, model_dim]\n",
    "        \n",
    "        # 4) Transformer expects shape [batch_size, seq_len, d_model]\n",
    "        #    We have 1 graph with N nodes => batch_size=1, seq_len=N\n",
    "        x = x.unsqueeze(0)  # shape [1, N, model_dim]\n",
    "        \n",
    "        # 5) Pass through Transformer\n",
    "        x = self.transformer_encoder(x)  # [1, N, model_dim]\n",
    "        \n",
    "        # 6) Pool or take first node, etc. (Your design choice)\n",
    "        #    E.g., average pooling over node dimension\n",
    "        x = x.mean(dim=1)  # [1, model_dim]\n",
    "        \n",
    "        # 7) Final output\n",
    "        out = self.out_layer(x)  # [1, 1]\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...\n",
    "def forward(self, graph_data, env_vector):\n",
    "    x = graph_data.x  # [num_nodes, node_feat_dim]\n",
    "    x = self.node_proj(x)     # [num_nodes, model_dim]\n",
    "    \n",
    "    env_emb = self.env_embed(env_vector.unsqueeze(0))  # [1, model_dim]\n",
    "    # Create a \"batch\" with shape [1, model_dim]. We'll treat it as an extra node\n",
    "    x = torch.cat([env_emb, x], dim=0)  # shape [num_nodes+1, model_dim]\n",
    "    \n",
    "    x = x.unsqueeze(0)  # [1, num_nodes+1, model_dim]\n",
    "    x = self.transformer_encoder(x)  # [1, num_nodes+1, model_dim]\n",
    "    \n",
    "    # For example, read out from the environment token (index 0):\n",
    "    env_token_output = x[:, 0, :]  # shape [1, model_dim]\n",
    "    out = self.out_layer(env_token_output)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 MSE/RMSE/R2 检验 → 测试model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty(): argument 'size' failed to unpack the object at pos 2 with error \"type must be tuple of ints,but got ellipsis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graphs[\u001b[38;5;241m0\u001b[39m], envs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# in a real scenario, you'd handle bigger batches\u001b[39;00m\n\u001b[0;32m     12\u001b[0m loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n\u001b[1;32m---> 14\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mGraphTransformerModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n",
      "Cell \u001b[1;32mIn[33], line 12\u001b[0m, in \u001b[0;36mGraphTransformerModel.__init__\u001b[1;34m(self, node_feat_dim, model_dim, num_heads, num_layers, env_dim, hidden_env)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Simple projection of node features up to model_dim\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_proj \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_feat_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# MLP to produce environment-based embedding\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv_embed \u001b[38;5;241m=\u001b[39m EnvEmbeddingMLP(env_dim\u001b[38;5;241m=\u001b[39menv_dim, \n\u001b[0;32m     16\u001b[0m                                  model_dim\u001b[38;5;241m=\u001b[39mmodel_dim,\n\u001b[0;32m     17\u001b[0m                                  hidden_dim\u001b[38;5;241m=\u001b[39mhidden_env)\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\nn\\modules\\linear.py:106\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features \u001b[38;5;241m=\u001b[39m in_features\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features \u001b[38;5;241m=\u001b[39m out_features\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\n\u001b[1;32m--> 106\u001b[0m     torch\u001b[38;5;241m.\u001b[39mempty((out_features, in_features), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs)\n\u001b[0;32m    107\u001b[0m )\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "\u001b[1;31mTypeError\u001b[0m: empty(): argument 'size' failed to unpack the object at pos 2 with error \"type must be tuple of ints,but got ellipsis\""
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch: list of (graph, env_vec) pairs\n",
    "    We'll combine them if you want to do multi-graph batches. \n",
    "    For simplicity, let's do 1 graph per batch.\n",
    "    \"\"\"\n",
    "    graphs, envs = zip(*batch)\n",
    "    return graphs[0], envs[0]  # in a real scenario, you'd handle bigger batches\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "model = GraphTransformerModel(...)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for graph_data, env_vector in loader:\n",
    "        optimizer.zero_grad()\n",
    "        # Suppose you want to predict some property from your graph (like BDE)\n",
    "        # We'll just do a random \"target\" for demonstration:\n",
    "        target = torch.tensor([42.0])  # dummy\n",
    "        pred = model(graph_data, env_vector)\n",
    "        loss = (pred - target).abs().mean()  # L1 or MSE, etc.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch} done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Number of graphs must match number of rows in env_df!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Suppose your environment DataFrame is called `df_env`.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Suppose it has columns:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#  [\"temperature\", \"seawater\", \"time\", \"concentration\", \"degradation_rate\"]\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# and each row matches one molecule in `pytorch_graphs`.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 1. Create dataset\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mMoleculeEnvDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyg_graphs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpytorch_graphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_env\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 2. Create dataloader\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m, in \u001b[0;36mMoleculeEnvDataset.__init__\u001b[1;34m(self, pyg_graphs, env_df)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pyg_graphs, env_df):\n\u001b[0;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m        pyg_graphs: list of PyG Data objects (one per molecule)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m        env_df: pandas DataFrame with environment columns and target\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m                (assumes rows align 1:1 with pyg_graphs)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pyg_graphs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(env_df), \\\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of graphs must match number of rows in env_df!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpyg_graphs \u001b[38;5;241m=\u001b[39m pyg_graphs\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv_df \u001b[38;5;241m=\u001b[39m env_df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Number of graphs must match number of rows in env_df!"
     ]
    }
   ],
   "source": [
    "# Suppose your environment DataFrame is called `df_env`.\n",
    "# Suppose it has columns:\n",
    "#  [\"temperature\", \"seawater\", \"time\", \"concentration\", \"degradation_rate\"]\n",
    "# and each row matches one molecule in `pytorch_graphs`.\n",
    "\n",
    "# 1. Create dataset\n",
    "dataset = MoleculeEnvDataset(pyg_graphs=pytorch_graphs, env_df=df_env)\n",
    "\n",
    "# 2. Create dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=my_collate)\n",
    "\n",
    "# 3. Initialize model\n",
    "num_node_features = 1  # if your x is [N,1], e.g. one-hot for C vs H\n",
    "env_input_dim = 4       # [temperature, concentration, time, maybe 'seawater']\n",
    "model = SimpleGraphModel(num_node_features=num_node_features,\n",
    "                         env_input_dim=env_input_dim,\n",
    "                         hidden_dim=128,\n",
    "                         output_dim=1)\n",
    "\n",
    "# 4. Train\n",
    "train_model(model, dataloader, device='cpu', epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_model(\u001b[43mmodel\u001b[49m, dataloader, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "train_model(model, dataloader, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. fixed code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'env_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pytorch_graphs))   \u001b[38;5;66;03m# Should be 20\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43menv_df\u001b[49m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'env_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(pytorch_graphs))   # Should be 20\n",
    "print(len(env_df))           # Must also be 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class MoleculeEnvDataset(Dataset):\n",
    "    def __init__(self, pyg_graphs, env_df):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pyg_graphs: list of PyG Data objects (molecules)\n",
    "            env_df: pandas DataFrame with environmental conditions & target\n",
    "        \"\"\"\n",
    "        self.pyg_graphs = pyg_graphs\n",
    "        self.env_df = env_df\n",
    "        \n",
    "        # 1. Expand molecule data to match env_df length\n",
    "        self.graphs_expanded = [pyg_graphs[i % len(pyg_graphs)] for i in range(len(env_df))]\n",
    "\n",
    "        # 2. Extract environmental conditions\n",
    "        self.env_features = torch.tensor(\n",
    "            self.env_df[[\"temperature\", \"seawater\", \"time\", \"concentration\"]].values, dtype=torch.float\n",
    "        )\n",
    "\n",
    "        # 3. Extract degradation rate as target\n",
    "        self.targets = torch.tensor(self.env_df[\"degradation_rate\"].values, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.env_df)  # Matches number of experimental conditions\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.graphs_expanded[idx]  # Get corresponding molecule\n",
    "        env_features = self.env_features[idx]  # Get environmental variables\n",
    "        target = self.targets[idx]  # Get degradation rate\n",
    "\n",
    "        return graph, env_features, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[42, 1], edge_index=[2, 44], edge_attr=[44, 2])\n",
      "tensor([35.6000,  1.0000, 30.0000, 70.0000])\n",
      "tensor(0.6709)\n"
     ]
    }
   ],
   "source": [
    "# 创建 Dataset\n",
    "dataset = MoleculeEnvDataset(pyg_graphs=pytorch_graphs, env_df=env_df)\n",
    "\n",
    "# 创建 DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# 检查 Dataset 结构\n",
    "graph, env_features, target = dataset[0]\n",
    "print(graph)  # Should be a PyG Data object\n",
    "print(env_features)  # Should be a tensor with 4 environmental variables\n",
    "print(target)  # Should be a single float value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'torch_geometric.data.data.Data'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 10\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m SimpleGraphModel(num_node_features\u001b[38;5;241m=\u001b[39mnum_node_features,\n\u001b[0;32m      5\u001b[0m                          env_input_dim\u001b[38;5;241m=\u001b[39menv_input_dim,\n\u001b[0;32m      6\u001b[0m                          hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[0;32m      7\u001b[0m                          output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, device, epochs)\u001b[0m\n\u001b[0;32m     10\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     11\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m graphs_batch, envs_batch, targets_batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     14\u001b[0m     graphs_batch \u001b[38;5;241m=\u001b[39m graphs_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m     envs_batch \u001b[38;5;241m=\u001b[39m envs_batch\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:211\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    212\u001b[0m         collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 212\u001b[0m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:240\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m             \u001b[38;5;66;03m# The sequence type may not support `copy()` / `__setitem__(index, item)`\u001b[39;00m\n\u001b[0;32m    234\u001b[0m             \u001b[38;5;66;03m# or `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[0;32m    235\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    236\u001b[0m                 collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[0;32m    237\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    238\u001b[0m             ]\n\u001b[1;32m--> 240\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'torch_geometric.data.data.Data'>"
     ]
    }
   ],
   "source": [
    "# 假设你的 GNN 结构如下：\n",
    "num_node_features = 1  # 节点特征\n",
    "env_input_dim = 4  # 环境变量：[温度，海水类型，时间，浓度]\n",
    "model = SimpleGraphModel(num_node_features=num_node_features,\n",
    "                         env_input_dim=env_input_dim,\n",
    "                         hidden_dim=128,\n",
    "                         output_dim=1)\n",
    "\n",
    "# 训练模型\n",
    "train_model(model, dataloader, device='cpu', epochs=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    temperature  seawater  time  concentration\n",
      "0          35.6         0    30             70\n",
      "1          35.6         0    30            700\n",
      "2          35.6         0    60             70\n",
      "3          35.6         0    60            700\n",
      "4          35.6         1    30             70\n",
      "5          35.6         1    30            700\n",
      "6          35.6         1    60             70\n",
      "7          35.6         1    60            700\n",
      "8          86.0         0    30             70\n",
      "9          86.0         0    30            700\n",
      "10         86.0         0    60             70\n",
      "11         86.0         0    60            700\n",
      "12         86.0         1    30             70\n",
      "13         86.0         1    30            700\n",
      "14         86.0         1    60             70\n",
      "15         86.0         1    60            700\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# 所有环境变量的可能取值\n",
    "temperature_values = [35.6, 86.0]\n",
    "seawater_values = [0, 1]  # 这里用 0 (sea), 1 (art) 代替字符串\n",
    "time_values = [30, 60]\n",
    "concentration_values = [70, 700]\n",
    "\n",
    "# **创建所有组合（16个环境变量组合）**\n",
    "env_conditions = list(itertools.product(\n",
    "    temperature_values, seawater_values, time_values, concentration_values\n",
    "))\n",
    "\n",
    "# 转为 Pandas DataFrame，便于查看\n",
    "env_df = pd.DataFrame(env_conditions, columns=[\"temperature\", \"seawater\", \"time\", \"concentration\"])\n",
    "print(env_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset, Data, Batch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class MoleculeEnvDataset(Dataset):\n",
    "    def __init__(self, pyg_graphs, env_df):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pyg_graphs: list of 20 PyG 分子图\n",
    "            env_df: 16 组环境变量\n",
    "        \"\"\"\n",
    "        self.pyg_graphs = pyg_graphs  # 20个分子\n",
    "        self.env_df = env_df\n",
    "\n",
    "        # **创建 (20 × 16) 组实验数据**\n",
    "        self.dataset = [\n",
    "            (self.pyg_graphs[i % len(self.pyg_graphs)], torch.tensor(env, dtype=torch.float))\n",
    "            for i in range(len(self.pyg_graphs) * len(self.env_df))\n",
    "            for env in self.env_df.values\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)  # 320 组数据\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph, env_features = self.dataset[idx]\n",
    "        return graph, env_features\n",
    "\n",
    "# **创建 Dataset**\n",
    "dataset = MoleculeEnvDataset(pyg_graphs=pytorch_graphs, env_df=env_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeEnvDataset(Dataset):\n",
    "    def __init__(self, pyg_graphs, env_df, target_values):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pyg_graphs: list of 20 PyG 分子图\n",
    "            env_df: 16 组环境变量\n",
    "            target_values: 320 组目标降解率 (每个分子在不同环境下的实验结果)\n",
    "        \"\"\"\n",
    "        self.pyg_graphs = pyg_graphs\n",
    "        self.env_df = env_df\n",
    "        self.target_values = target_values  # 目标值 (320个)\n",
    "\n",
    "        # **创建 (20 × 16) 组实验数据**\n",
    "        self.dataset = [\n",
    "            (self.pyg_graphs[i % len(self.pyg_graphs)],  # Graph\n",
    "             torch.tensor(env, dtype=torch.float),       # 环境变量\n",
    "             torch.tensor(self.target_values[i], dtype=torch.float))  # 目标值\n",
    "            for i in range(len(self.pyg_graphs) * len(self.env_df))\n",
    "            for env in self.env_df.values\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)  # 320 组数据\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph, env_features, target = self.dataset[idx]\n",
    "        return graph, env_features, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mmy_collate)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# **检查 DataLoader**\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m graphs_batch, env_features_batch, targets_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(graphs_batch)  \u001b[38;5;66;03m# PyG DataBatch\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(env_features_batch\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# (batch_size, 4)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m, in \u001b[0;36mmy_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmy_collate\u001b[39m(batch):\n\u001b[1;32m----> 2\u001b[0m     graphs, env_features, targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)  \u001b[38;5;66;03m# 拆分 Graph, 环境变量, 目标值\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     graphs_batch \u001b[38;5;241m=\u001b[39m Batch\u001b[38;5;241m.\u001b[39mfrom_data_list(graphs)  \u001b[38;5;66;03m# PyG 批量处理\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     env_features_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(env_features)  \u001b[38;5;66;03m# 转 Tensor\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "def my_collate(batch):\n",
    "    graphs, env_features, targets = zip(*batch)  # 拆分 Graph, 环境变量, 目标值\n",
    "    graphs_batch = Batch.from_data_list(graphs)  # PyG 批量处理\n",
    "    env_features_batch = torch.stack(env_features)  # 转 Tensor\n",
    "    targets_batch = torch.stack(targets)  # 转 Tensor\n",
    "    return graphs_batch, env_features_batch, targets_batch\n",
    "\n",
    "# **创建 DataLoader**\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=my_collate)\n",
    "\n",
    "# **检查 DataLoader**\n",
    "graphs_batch, env_features_batch, targets_batch = next(iter(dataloader))\n",
    "print(graphs_batch)  # PyG DataBatch\n",
    "print(env_features_batch.shape)  # (batch_size, 4)\n",
    "print(targets_batch.shape)  # (batch_size,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 11\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m SimpleGraphModel(num_node_features\u001b[38;5;241m=\u001b[39mnum_node_features,\n\u001b[0;32m      6\u001b[0m                          env_input_dim\u001b[38;5;241m=\u001b[39menv_input_dim,\n\u001b[0;32m      7\u001b[0m                          hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[0;32m      8\u001b[0m                          output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# **训练模型**\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, device, epochs)\u001b[0m\n\u001b[0;32m     10\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     11\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m graphs_batch, envs_batch, targets_batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     14\u001b[0m     graphs_batch \u001b[38;5;241m=\u001b[39m graphs_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m     envs_batch \u001b[38;5;241m=\u001b[39m envs_batch\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "# 假设 GNN 结构如下：\n",
    "num_node_features = 1  # 节点特征\n",
    "env_input_dim = 4  # 环境变量：[温度，海水类型，时间，浓度]\n",
    "\n",
    "model = SimpleGraphModel(num_node_features=num_node_features,\n",
    "                         env_input_dim=env_input_dim,\n",
    "                         hidden_dim=128,\n",
    "                         output_dim=1)\n",
    "\n",
    "# **训练模型**\n",
    "train_model(model, dataloader, device='cpu', epochs=20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alfabet-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
