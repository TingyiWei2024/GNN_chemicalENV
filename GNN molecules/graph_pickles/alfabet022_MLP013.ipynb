{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA \n",
    "1. input molecules graph data √\n",
    "2. input correct env variable √  - btw: art is what seawater?\n",
    "3. connect these data by Useing environmental variables as Transformer Positional Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load molecules graph datas from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 graphs\n"
     ]
    }
   ],
   "source": [
    "## Load the molecular data (.pkl) for molecules with Targeted BDE & BDFE \n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "folder_path = r\"C:\\Users\\80710\\OneDrive - Imperial College London\\2025 engineering\\GNN molecules\\graph_pickles\"\n",
    "\n",
    "# Get all .pkl file paths in the folder\n",
    "pkl_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".pkl\")]\n",
    "\n",
    "# Load all graphs\n",
    "graph_list = []\n",
    "for file_path in pkl_files:\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        graph = pickle.load(file)  # Load each .pkl graph\n",
    "        graph_list.append(graph)  # Store in a list\n",
    "\n",
    "print(f\"Loaded {len(graph_list)} graphs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>rdkit_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>C</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>C</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>C</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_41</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_49</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_47</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_33</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_32</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_30</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_40</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_28</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_46</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_59</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_37</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_61</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_56</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_27</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_44</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_62</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_52</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_36</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_23</th>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol  rdkit_idx\n",
       "0         C        0.0\n",
       "1         C        1.0\n",
       "2         C        2.0\n",
       "3         C        3.0\n",
       "4         C        4.0\n",
       "5         C        5.0\n",
       "6         C        6.0\n",
       "7         C        7.0\n",
       "8         C        8.0\n",
       "9         C        9.0\n",
       "10        C       10.0\n",
       "11        C       11.0\n",
       "12        C       12.0\n",
       "13        C       13.0\n",
       "14        C       14.0\n",
       "15        C       15.0\n",
       "16        C       16.0\n",
       "17        C       17.0\n",
       "18        C       18.0\n",
       "19        C       19.0\n",
       "20        C       20.0\n",
       "21        C       21.0\n",
       "22        C       22.0\n",
       "H_41      H        NaN\n",
       "H_49      H        NaN\n",
       "H_47      H        NaN\n",
       "H_33      H        NaN\n",
       "H_32      H        NaN\n",
       "H_30      H        NaN\n",
       "H_40      H        NaN\n",
       "H_28      H        NaN\n",
       "H_46      H        NaN\n",
       "H_59      H        NaN\n",
       "H_37      H        NaN\n",
       "H_61      H        NaN\n",
       "H_56      H        NaN\n",
       "H_27      H        NaN\n",
       "H_44      H        NaN\n",
       "H_62      H        NaN\n",
       "H_52      H        NaN\n",
       "H_36      H        NaN\n",
       "H_23      H        NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>bond_index</th>\n",
       "      <th>bde_pred</th>\n",
       "      <th>bdfe_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.382645</td>\n",
       "      <td>75.711845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>H_23</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.077171</td>\n",
       "      <td>91.049126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.872452</td>\n",
       "      <td>71.412849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>H_27</td>\n",
       "      <td>29.0</td>\n",
       "      <td>97.163109</td>\n",
       "      <td>87.689636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.041306</td>\n",
       "      <td>70.000282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>H_28</td>\n",
       "      <td>30.0</td>\n",
       "      <td>95.392189</td>\n",
       "      <td>86.257263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>83.115479</td>\n",
       "      <td>66.995277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>H_30</td>\n",
       "      <td>32.0</td>\n",
       "      <td>94.518471</td>\n",
       "      <td>84.748619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>H_32</td>\n",
       "      <td>34.0</td>\n",
       "      <td>93.767830</td>\n",
       "      <td>84.237808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>86.171143</td>\n",
       "      <td>71.943573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>H_33</td>\n",
       "      <td>35.0</td>\n",
       "      <td>93.715744</td>\n",
       "      <td>84.072701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>H_36</td>\n",
       "      <td>38.0</td>\n",
       "      <td>98.747513</td>\n",
       "      <td>89.695892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>H_37</td>\n",
       "      <td>39.0</td>\n",
       "      <td>95.855804</td>\n",
       "      <td>86.941345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>H_40</td>\n",
       "      <td>42.0</td>\n",
       "      <td>94.971001</td>\n",
       "      <td>85.988342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>H_41</td>\n",
       "      <td>43.0</td>\n",
       "      <td>86.859306</td>\n",
       "      <td>75.766228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>79.460541</td>\n",
       "      <td>64.253868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11</td>\n",
       "      <td>H_44</td>\n",
       "      <td>46.0</td>\n",
       "      <td>97.184883</td>\n",
       "      <td>88.282661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12</td>\n",
       "      <td>H_46</td>\n",
       "      <td>48.0</td>\n",
       "      <td>95.408730</td>\n",
       "      <td>86.714386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>H_47</td>\n",
       "      <td>49.0</td>\n",
       "      <td>92.920937</td>\n",
       "      <td>84.154495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>14</td>\n",
       "      <td>H_49</td>\n",
       "      <td>51.0</td>\n",
       "      <td>89.283218</td>\n",
       "      <td>79.903214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>15.0</td>\n",
       "      <td>82.408630</td>\n",
       "      <td>67.338509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16</td>\n",
       "      <td>H_52</td>\n",
       "      <td>54.0</td>\n",
       "      <td>98.126961</td>\n",
       "      <td>89.117233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>18</td>\n",
       "      <td>H_56</td>\n",
       "      <td>58.0</td>\n",
       "      <td>96.827797</td>\n",
       "      <td>87.840210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>19</td>\n",
       "      <td>H_59</td>\n",
       "      <td>61.0</td>\n",
       "      <td>95.608147</td>\n",
       "      <td>86.592361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>20</td>\n",
       "      <td>H_61</td>\n",
       "      <td>63.0</td>\n",
       "      <td>96.082130</td>\n",
       "      <td>87.054794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>21.0</td>\n",
       "      <td>79.644073</td>\n",
       "      <td>64.361122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>22</td>\n",
       "      <td>H_62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>97.762428</td>\n",
       "      <td>88.862091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source target  bond_index    bde_pred  bdfe_pred\n",
       "0        0      1         0.0   89.382645  75.711845\n",
       "1        0   H_23        25.0  100.077171  91.049126\n",
       "2        1      2         1.0   85.872452  71.412849\n",
       "3        1   H_27        29.0   97.163109  87.689636\n",
       "4        2      3         2.0   85.041306  70.000282\n",
       "5        2   H_28        30.0   95.392189  86.257263\n",
       "6        3      4         3.0   83.115479  66.995277\n",
       "7        3   H_30        32.0   94.518471  84.748619\n",
       "8        4      5         NaN         NaN        NaN\n",
       "9        4     10         NaN         NaN        NaN\n",
       "10       4   H_32        34.0   93.767830  84.237808\n",
       "11       5      6         5.0   86.171143  71.943573\n",
       "12       5      7         NaN         NaN        NaN\n",
       "13       5   H_33        35.0   93.715744  84.072701\n",
       "14       6   H_36        38.0   98.747513  89.695892\n",
       "15       7      8         NaN         NaN        NaN\n",
       "16       7   H_37        39.0   95.855804  86.941345\n",
       "17       8      9         NaN         NaN        NaN\n",
       "18       8   H_40        42.0   94.971001  85.988342\n",
       "19       9     10         NaN         NaN        NaN\n",
       "20       9     21         NaN         NaN        NaN\n",
       "21       9   H_41        43.0   86.859306  75.766228\n",
       "22      10     11        10.0   79.460541  64.253868\n",
       "23      10     12         NaN         NaN        NaN\n",
       "24      11   H_44        46.0   97.184883  88.282661\n",
       "25      12     13         NaN         NaN        NaN\n",
       "26      12   H_46        48.0   95.408730  86.714386\n",
       "27      13     14         NaN         NaN        NaN\n",
       "28      13   H_47        49.0   92.920937  84.154495\n",
       "29      14     15         NaN         NaN        NaN\n",
       "30      14     21         NaN         NaN        NaN\n",
       "31      14   H_49        51.0   89.283218  79.903214\n",
       "32      15     16        15.0   82.408630  67.338509\n",
       "33      15     17         NaN         NaN        NaN\n",
       "34      15     18         NaN         NaN        NaN\n",
       "35      16   H_52        54.0   98.126961  89.117233\n",
       "36      18     19         NaN         NaN        NaN\n",
       "37      18   H_56        58.0   96.827797  87.840210\n",
       "38      19     20         NaN         NaN        NaN\n",
       "39      19   H_59        61.0   95.608147  86.592361\n",
       "40      20     21         NaN         NaN        NaN\n",
       "41      20   H_61        63.0   96.082130  87.054794\n",
       "42      21     22        21.0   79.644073  64.361122\n",
       "43      22   H_62        64.0   97.762428  88.862091"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 检查\n",
    "import pandas as pd\n",
    "\n",
    "# Select the first graph for visualization\n",
    "nx_graph = graph_list[0]\n",
    "\n",
    "# Convert node data to DataFrame\n",
    "node_data = pd.DataFrame.from_dict(dict(nx_graph.nodes(data=True)), orient=\"index\")\n",
    "\n",
    "# Convert edge data to DataFrame\n",
    "edge_data = pd.DataFrame.from_records([(u, v, d) for u, v, d in nx_graph.edges(data=True)], \n",
    "                                      columns=[\"source\", \"target\", \"attributes\"])\n",
    "\n",
    "# Expand edge attributes\n",
    "if not edge_data.empty and isinstance(edge_data.iloc[0][\"attributes\"], dict):\n",
    "    attr_df = edge_data[\"attributes\"].apply(pd.Series)  # Convert dict to columns\n",
    "    edge_data = pd.concat([edge_data.drop(columns=[\"attributes\"]), attr_df], axis=1)\n",
    "\n",
    "# Display DataFrames\n",
    "from IPython.display import display\n",
    "display(node_data)\n",
    "display(edge_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking: 为什么rdix里H对应的都是NAN 我们转化时用的是H-H 单H 键不需要 再进入rdix编号\n",
    "\n",
    "备注：os.listdir... 列出文件夹中文件名称，迭代获取，保留.pkl,output list\n",
    "     \"rb\"对口pkl二进制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Graph 1: 42 nodes, 44 edges\n",
      "Converted Graph 2: 43 nodes, 45 edges\n",
      "Converted Graph 3: 52 nodes, 56 edges\n",
      "Converted Graph 4: 54 nodes, 58 edges\n",
      "Converted Graph 5: 56 nodes, 60 edges\n",
      "Converted Graph 6: 56 nodes, 60 edges\n",
      "Converted Graph 7: 58 nodes, 62 edges\n",
      "Converted Graph 8: 58 nodes, 62 edges\n",
      "Converted Graph 9: 60 nodes, 64 edges\n",
      "Converted Graph 10: 60 nodes, 64 edges\n",
      "Converted Graph 11: 62 nodes, 66 edges\n",
      "Converted Graph 12: 62 nodes, 66 edges\n",
      "Converted Graph 13: 46 nodes, 48 edges\n",
      "Converted Graph 14: 48 nodes, 50 edges\n",
      "Converted Graph 15: 52 nodes, 54 edges\n",
      "Converted Graph 16: 52 nodes, 54 edges\n",
      "Converted Graph 17: 53 nodes, 55 edges\n",
      "Converted Graph 18: 53 nodes, 55 edges\n",
      "Converted Graph 19: 48 nodes, 52 edges\n",
      "Converted Graph 20: 48 nodes, 52 edges\n",
      "\n",
      " Total converted graphs: 20\n"
     ]
    }
   ],
   "source": [
    "## Convert Graphs to PyTorch Geometric Format for GNN model\n",
    "# 方便训练和GNN计算，转化为PyG\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "\n",
    "# Path to dataset folder (Update this)\n",
    "folder_path = r\"C:\\Users\\80710\\OneDrive - Imperial College London\\2025 engineering\\GNN molecules\\graph_pickles\"\n",
    "\n",
    "# Get all .pkl file paths\n",
    "pkl_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".pkl\")]\n",
    "\n",
    "# List to store PyTorch Geometric graphs\n",
    "pytorch_graphs = []\n",
    "\n",
    "# **Function to handle missing hydrogen atom labels**\n",
    "def clean_node_labels(node_data):\n",
    "    \"\"\"Replace NaN hydrogen labels with unique identifiers.\"\"\"\n",
    "    return {node: idx if not pd.isna(node) else f\"H_{idx}\" for idx, node in enumerate(node_data)}\n",
    "\n",
    "# 分别提取节点和边的数据重构graph\n",
    "# **Loop through each .pkl file and convert to PyG format**\n",
    "for i, file_path in enumerate(pkl_files):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        nx_graph = pickle.load(file)  # Load NetworkX graph\n",
    "\n",
    "        if isinstance(nx_graph, nx.Graph):\n",
    "            # **Relabel nodes to avoid NaN values**\n",
    "            mapping = clean_node_labels(nx_graph.nodes())\n",
    "            nx_graph = nx.relabel_nodes(nx_graph, mapping)\n",
    "\n",
    "            # **Convert Edges to PyG format (edge_index)**\n",
    "            edge_index = torch.tensor(list(nx_graph.edges()), dtype=torch.long).T\n",
    "            if edge_index.numel() == 0:  # Handle cases with no edges\n",
    "                edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "            # **Extract Node Features (Use Atomic Symbols)**\n",
    "            first_node = next(iter(nx_graph.nodes), None)\n",
    "            if first_node is not None and \"symbol\" in nx_graph.nodes[first_node]:\n",
    "                node_features = torch.tensor(\n",
    "                    [[1 if nx_graph.nodes[n][\"symbol\"] == \"C\" else 0] for n in nx_graph.nodes()],\n",
    "                    dtype=torch.float\n",
    "                )  # One-hot encoding Carbon (C) vs Hydrogen (H)\n",
    "            else:\n",
    "                node_features = torch.zeros((len(nx_graph.nodes()), 1), dtype=torch.float)  # Default: 1D zero feature\n",
    "\n",
    "            # **Extract Edge Features (BDE, BDFE) - Handle NoneType**\n",
    "            edge_features_list = []\n",
    "            for u, v in nx_graph.edges():\n",
    "                bde = nx_graph[u][v].get(\"bde_pred\", 0.0)  # Replace None with 0.0\n",
    "                bdfe = nx_graph[u][v].get(\"bdfe_pred\", 0.0)  # Replace None with 0.0\n",
    "                edge_features_list.append([bde if bde is not None else 0.0, bdfe if bdfe is not None else 0.0])\n",
    "\n",
    "            edge_features = torch.tensor(edge_features_list, dtype=torch.float) if edge_features_list else None\n",
    "\n",
    "            # **Create PyG Graph**\n",
    "            pyg_graph = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "\n",
    "            # **Store Processed Graph**\n",
    "            pytorch_graphs.append(pyg_graph)\n",
    "            print(f\"Converted Graph {i+1}: {len(nx_graph.nodes)} nodes, {len(nx_graph.edges)} edges\")\n",
    "\n",
    "print(f\"\\n Total converted graphs: {len(pytorch_graphs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[42, 1], edge_index=[2, 44], edge_attr=[44, 2])\n"
     ]
    }
   ],
   "source": [
    "print(pytorch_graphs[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the environmental variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data number         float64\n",
      "temperature         float64\n",
      "seawater            float64\n",
      "concentration         int64\n",
      "time                  int64\n",
      "BDE                 float64\n",
      "BDFE                float64\n",
      "energy              float64\n",
      "degradation_rate    float64\n",
      "dtype: object\n",
      "data number         0\n",
      "temperature         0\n",
      "seawater            0\n",
      "concentration       0\n",
      "time                0\n",
      "BDE                 0\n",
      "BDFE                0\n",
      "energy              0\n",
      "degradation_rate    0\n",
      "dtype: int64\n",
      "   data number  temperature  seawater  concentration  time        BDE  \\\n",
      "0          1.0         35.6       0.0             70    30  91.907407   \n",
      "1          1.0         35.6       0.0             70    30  91.700000   \n",
      "2          1.0         35.6       0.0             70    30  91.674194   \n",
      "3          1.0         35.6       0.0             70    30  91.657576   \n",
      "4          1.0         35.6       0.0             70    30  91.778378   \n",
      "\n",
      "        BDFE       energy  degradation_rate  \n",
      "0  80.962963  -975.632487          0.670914  \n",
      "1  80.714815 -1014.888178          0.680071  \n",
      "2  80.451613 -1054.141175          0.655230  \n",
      "3  80.375758 -1093.397252          0.625193  \n",
      "4  80.664865 -1171.908573          0.605853  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load environmental data from Excel\n",
    "env_data_path = r\"C:\\Users\\80710\\OneDrive - Imperial College London\\2025 engineering\\GNN molecules\\graph_pickles\\dataset02.xlsx\"\n",
    "df_env = pd.read_excel(env_data_path, engine='openpyxl')\n",
    "\n",
    "# Columns of interest\n",
    "env_columns = [\"temperature\", \"seawater\", \"time\", \"concentration\"]\n",
    "\n",
    "# Convert 'seawater' column properly\n",
    "df_env[\"seawater\"] = df_env[\"seawater\"].map({\"sea\": 0, \"art\": 1}).astype(float)\n",
    "\n",
    "# Convert all columns to numeric (force object types to float)\n",
    "df_env = df_env.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "df_env = df_env.drop(columns=['component'])\n",
    "\n",
    "\n",
    "# Fill missing values (optional, based on needs)\n",
    "df_env = df_env.dropna()\n",
    "\n",
    "\n",
    "# Print column types again to verify\n",
    "print(df_env.dtypes)\n",
    "print(df_env.isna().sum())  # Count NaNs in each column\n",
    "\n",
    "print(df_env.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use environmental variables as Transformer Positional Encoding connect\n",
    "\n",
    "simply use nx graph is enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "class MoleculeEnvDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, graphs, df_env):\n",
    "        self.graphs = graphs  # List of PyG Data objects\n",
    "        self.df_env = df_env  # Environmental features & target values (DataFrame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.graphs[idx]  # PyG Data object\n",
    "\n",
    "        # Convert environmental features to tensor\n",
    "        env_features = torch.tensor(self.df_env.iloc[idx, :-1].values, dtype=torch.float32)  \n",
    "        target = torch.tensor(self.df_env.iloc[idx, -1], dtype=torch.float32)  # Last column is target\n",
    "\n",
    "        # **Store them inside the graph object**\n",
    "        graph.env_features = env_features.unsqueeze(0)  # Ensure correct shape\n",
    "        graph.targets = target.unsqueeze(0)  \n",
    "\n",
    "        return graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MoleculeEnvDataset(Dataset):\n",
    "    def __init__(self, graphs, df_env):\n",
    "        self.graphs = graphs\n",
    "        self.df_env = df_env.reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.graphs[idx]  # PyG graph\n",
    "\n",
    "        # Extract environment features\n",
    "        env_values = df_env.iloc[idx, [1, 2, 3, 4]].values  # Extract temperature, seawater, concentration, time\n",
    "        print(f\"Index {idx} - Env Values:\", env_values)  # Debugging print\n",
    "\n",
    "        # Convert to tensor (use .astype(float) to prevent PyTorch issues)\n",
    "        env_features = torch.tensor(env_values.astype(float), dtype=torch.float32)\n",
    "\n",
    "        # Extract and convert target value\n",
    "        target_value = df_env.iloc[idx, -1]\n",
    "        print(f\"Index {idx} - Target Value:\", target_value)  # Debugging print\n",
    "\n",
    "        target = torch.tensor(float(target_value), dtype=torch.float32)  # Ensure it's a single float\n",
    "\n",
    "        return graph, env_features, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1  建立Build DataLoader\n",
    "PYG的Data对象代表图形，图形在节点和边缘的数量上有所不同。默认的DataLoader试图像张量一样堆叠它们，是不行滴。\n",
    " Custom Collate？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "def my_collate(batch):\n",
    "    graphs, envs, targets = zip(*batch)\n",
    "    graphs = Batch.from_data_list(graphs)  # Batch PyG graphs\n",
    "    envs = torch.stack(envs)  # Convert list of tensors to a batch tensor\n",
    "    targets = torch.stack(targets)  # Convert list of targets to tensor\n",
    "\n",
    "    return graphs, envs, targets\n",
    "\n",
    "# Create Dataset\n",
    "dataset = MoleculeEnvDataset(graph_list, df_env)\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=my_collate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 建立 env + molecules graph层 → 建立GNN\n",
    "由于PYG将多个图批量分为一个大图结构，因此我们需要data.batch来确保每个节点都会收到其相应图的正确环境嵌入\n",
    "1.PYG将多个图形组合在一起→来自不同图形的节点被连接\n",
    "2.data.batch tracks nodes属于哪个图。\n",
    "3.我们使用env_pos_emb[data.batch]添加每个节点的正确环境效果\n",
    "4.这确保每个节点都会获取其相应的环境编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class EnvPositionalEncoder(nn.Module):\n",
    "    \"\"\" Encodes environmental variables into a learnable embedding. \"\"\"\n",
    "    def __init__(self, env_input_dim, d_model, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(env_input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, d_model)\n",
    "        )\n",
    "\n",
    "    def forward(self, env_features):\n",
    "        return self.mlp(env_features)\n",
    "\n",
    "class SimpleGraphModel(nn.Module):\n",
    "    def __init__(self, num_node_features, env_input_dim, hidden_dim=128, output_dim=1):\n",
    "        super(SimpleGraphModel, self).__init__()\n",
    "        \n",
    "        # Graph neural network layers\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Environment encoding\n",
    "        self.env_encoder = EnvPositionalEncoder(env_input_dim, hidden_dim)\n",
    "\n",
    "        # Final MLP for regression\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, data, env_features):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        # Graph embeddings\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        graph_embedding = x.mean(dim=0)  # Global pooling (mean over all nodes)\n",
    "\n",
    "        # Environment embeddings\n",
    "        env_embedding = self.env_encoder(env_features)\n",
    "\n",
    "        # Concatenate both representations\n",
    "        combined = torch.cat([graph_embedding, env_embedding], dim=-1)\n",
    "\n",
    "        # Predict degradation rate\n",
    "        return self.mlp(combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 MSE/RMSE/R2 检验 → 测试model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def train_model(model, dataloader, epochs=20):\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for graphs_batch, envs_batch, targets_batch in dataloader:\n",
    "            graphs_batch = graphs_batch.to(device)\n",
    "            envs_batch = envs_batch.to(device)\n",
    "            targets_batch = targets_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(graphs_batch, envs_batch)\n",
    "\n",
    "            # Compute MSE Loss\n",
    "            loss = criterion(outputs, targets_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * targets_batch.size(0)\n",
    "            total_samples += targets_batch.size(0)\n",
    "\n",
    "        avg_loss = total_loss / total_samples  # Compute average MSE loss\n",
    "\n",
    "        # === Evaluation Step ===\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds, gts = [], []\n",
    "            \n",
    "            for graphs_batch, envs_batch, targets_batch in dataloader:\n",
    "                graphs_batch = graphs_batch.to(device)\n",
    "                envs_batch = envs_batch.to(device)\n",
    "                targets_batch = targets_batch.to(device)\n",
    "\n",
    "                out = model(graphs_batch, envs_batch)\n",
    "                preds.append(out.cpu())\n",
    "                gts.append(targets_batch.cpu())\n",
    "\n",
    "            preds = torch.cat(preds).numpy()\n",
    "            gts = torch.cat(gts).numpy()\n",
    "\n",
    "            mse_val = F.mse_loss(torch.tensor(preds), torch.tensor(gts)).item()\n",
    "            rmse_val = math.sqrt(mse_val)\n",
    "            r2_val = r2_score(gts, preds)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs} - Train MSE: {avg_loss:.4f}, Val RMSE: {rmse_val:.4f}, R²: {r2_val:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "dataloader = DataLoader(pytorch_graphs, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m env_input_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m  \u001b[38;5;66;03m# [temperature, seawater, time, concentration]\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m SimpleGraphModel(num_node_features, env_input_dim, hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[73], line 19\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, epochs)\u001b[0m\n\u001b[0;32m     16\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     17\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m graphs_batch, envs_batch, targets_batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     20\u001b[0m     graphs_batch \u001b[38;5;241m=\u001b[39m graphs_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     21\u001b[0m     envs_batch \u001b[38;5;241m=\u001b[39m envs_batch\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# Initialize and Train Model\n",
    "num_node_features = 2  # BDE BDFE\n",
    "env_input_dim = 4  # [temperature, seawater, time, concentration]\n",
    "model = SimpleGraphModel(num_node_features, env_input_dim, hidden_dim=128, output_dim=1)\n",
    "\n",
    "train_model(model, dataloader, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[73], line 19\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, epochs)\u001b[0m\n\u001b[0;32m     16\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     17\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m graphs_batch, envs_batch, targets_batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     20\u001b[0m     graphs_batch \u001b[38;5;241m=\u001b[39m graphs_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     21\u001b[0m     envs_batch \u001b[38;5;241m=\u001b[39m envs_batch\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "train_model(model, dataloader, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training + fixed code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graphs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check dataset output format before dataloader\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m MoleculeEnvDataset(\u001b[43mgraphs\u001b[49m, df_env)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'graphs' is not defined"
     ]
    }
   ],
   "source": [
    "# Check dataset output format before dataloader\n",
    "dataset = MoleculeEnvDataset(graphs, df_env)\n",
    "print(dataset[0])  # Expecting (graph, env_features, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "Index 0 - Env Values: [35.6  0.  70.  30. ]\n",
      "Index 0 - Target Value: 0.6709138594659749\n",
      "(Data(x=[42, 1], edge_index=[2, 44], edge_attr=[44, 2]), tensor([35.6000,  0.0000, 70.0000, 30.0000]), tensor(0.6709))\n"
     ]
    }
   ],
   "source": [
    "dataset = MoleculeEnvDataset(pytorch_graphs, df_env)\n",
    "print(len(dataset))  # Should print the total number of graphs\n",
    "print(dataset[0])    # Should print (graph, env_features, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[220, 1], edge_index=[2, 236], edge_attr=[236, 2], batch=[220], ptr=[5])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    break  # Stop after one batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'env_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m      2\u001b[0m     graphs_batch \u001b[38;5;241m=\u001b[39m batch  \u001b[38;5;66;03m# Entire batch is a DataBatch object\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     envs_batch \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_features\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Ensure this attribute exists\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     targets_batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mtargets\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch_geometric\\data\\data.py:561\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_store\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object was created by an older version of PyG. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this error occurred while loading an already existing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset, remove the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory in the dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot folder and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch_geometric\\data\\storage.py:96\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'env_features'"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    graphs_batch = batch  # Entire batch is a DataBatch object\n",
    "    envs_batch = batch.env_features.to(device)  # Ensure this attribute exists\n",
    "    targets_batch = batch.targets.to(device)    # Ensure this attribute exists\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alfabet-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
