{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/NREL/alfabet.git@0.2.2\n",
      "  Cloning https://github.com/NREL/alfabet.git (to revision 0.2.2) to c:\\users\\80710\\appdata\\local\\temp\\pip-req-build-_y5u9hg8\n",
      "  Resolved https://github.com/NREL/alfabet.git to commit 9942cbd6fceeed549e8126692b15bb135e103f5a\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from alfabet==0.2.2) (2.2.3)\n",
      "Requirement already satisfied: nfp>=0.3.6 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from alfabet==0.2.2) (0.3.12)\n",
      "Requirement already satisfied: tqdm in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from alfabet==0.2.2) (4.66.5)\n",
      "Requirement already satisfied: pooch in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from alfabet==0.2.2) (1.8.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from alfabet==0.2.2) (1.4.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from alfabet==0.2.2) (0.24.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from nfp>=0.3.6->alfabet==0.2.2) (1.26.4)\n",
      "Requirement already satisfied: networkx>2.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from nfp>=0.3.6->alfabet==0.2.2) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from pandas->alfabet==0.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from pandas->alfabet==0.2.2) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from pandas->alfabet==0.2.2) (2024.2)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from pooch->alfabet==0.2.2) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from pooch->alfabet==0.2.2) (24.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from pooch->alfabet==0.2.2) (2.32.3)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from scikit-learn->alfabet==0.2.2) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from scikit-learn->alfabet==0.2.2) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from tqdm->alfabet==0.2.2) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->alfabet==0.2.2) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from requests>=2.19.0->pooch->alfabet==0.2.2) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from requests>=2.19.0->pooch->alfabet==0.2.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from requests>=2.19.0->pooch->alfabet==0.2.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from requests>=2.19.0->pooch->alfabet==0.2.2) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/NREL/alfabet.git 'C:\\Users\\80710\\AppData\\Local\\Temp\\pip-req-build-_y5u9hg8'\n",
      "  Running command git checkout -q 9942cbd6fceeed549e8126692b15bb135e103f5a\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/NREL/alfabet.git@0.2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alfabet.drawing import draw_mol_outlier\n",
    "from alfabet.fragment import canonicalize_smiles\n",
    "from alfabet.neighbors import find_neighbor_bonds\n",
    "from alfabet.prediction import predict_bdes, check_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.2'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import alfabet\n",
    "alfabet.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024.03.5'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdkit.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bde_graph_selective_hs(smiles: str, bde_df) -> nx.Graph:\n",
    "    \"\"\"\n",
    "    Build a NetworkX graph from the *original (heavy-atom)* RDKit Mol:\n",
    "      - Keep all heavy-atom ring & skeleton bonds from the SMILES.\n",
    "      - Add new H-X bonds (i.e., only the hydrogens needed) when a row in bde_df indicates\n",
    "        a predicted bond that doesn't already exist in the heavy-atom Mol.\n",
    "    \n",
    "    bde_df is expected to have columns:\n",
    "       - start_atom, end_atom: integer indexes or placeholders\n",
    "       - bde_pred, bdfe_pred, etc.: predicted data for each bond\n",
    "       - possibly bond_index (optional)\n",
    "    \n",
    "    Steps:\n",
    "       1) Parse the SMILES without adding Hs (just once).\n",
    "       2) Build a base Nx graph with all heavy-atom nodes & edges.\n",
    "       3) Iterate over bde_df. If the row corresponds to an existing heavy–heavy bond,\n",
    "          update the Nx edge with predicted data. If the row corresponds to an H–X bond,\n",
    "          add the H node + edge and store the predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Parse the SMILES into an RDKit Mol (no AddHs)\n",
    "    base_mol = Chem.MolFromSmiles(smiles)\n",
    "    if base_mol is None:\n",
    "        # Handle parse error, e.g. return empty graph\n",
    "        return nx.Graph()\n",
    "\n",
    "    # 2. Create an Nx graph, optionally store the RDKit Mol for reference\n",
    "    G = nx.Graph(mol=base_mol)\n",
    "\n",
    "    # 3. Add heavy-atom nodes\n",
    "    #    We'll store:\n",
    "    #      - 'symbol': e.g. 'C', 'O', 'N', etc.\n",
    "    #      - 'rdkit_idx': the integer index assigned by RDKit\n",
    "    #    Feel free to store other attributes as well.\n",
    "    for atom in base_mol.GetAtoms():\n",
    "        atom_idx = atom.GetIdx()\n",
    "        G.add_node(atom_idx, \n",
    "                   symbol=atom.GetSymbol(),\n",
    "                   rdkit_idx=atom_idx)\n",
    "\n",
    "    # 4. Add edges for all heavy-atom bonds in the original (no-H) Mol\n",
    "    #    We won't attach any BDE predictions yet (set them to None).\n",
    "    #    We'll also store a default bond_index=None if desired.\n",
    "    for bond in base_mol.GetBonds():\n",
    "        a1 = bond.GetBeginAtomIdx()\n",
    "        a2 = bond.GetEndAtomIdx()\n",
    "        G.add_edge(a1, a2,\n",
    "                   bond_index=None,\n",
    "                   bde_pred=None,\n",
    "                   bdfe_pred=None)\n",
    "\n",
    "    # 5. Iterate over bde_df.  We'll assume the columns are something like:\n",
    "    #     start_atom, end_atom, bde_pred, bdfe_pred, bond_index, etc.\n",
    "    #    - For heavy–heavy predictions, update the existing edge with predicted data.\n",
    "    #    - For H–X predictions, add the new hydrogen node & edge if not present.\n",
    "    #    - This approach assumes that for an H–X bond, either start_atom or end_atom\n",
    "    #      is a placeholder for hydrogen or an integer representing \"H\" in your dataset.\n",
    "    for _, row in bde_df.iterrows():\n",
    "        s = row['start_atom']\n",
    "        e = row['end_atom']\n",
    "        \n",
    "        # Attempt to interpret s and e in the context of the base mol\n",
    "        # We'll use a simple rule:\n",
    "        #  - If the index is >= base_mol.GetNumAtoms(), treat it as \"this is a hydrogen\"\n",
    "        #  - Or you could have a special marker like -1 for hydrogen\n",
    "        #    (depends on how your data is structured)\n",
    "        \n",
    "        # We also store predicted data\n",
    "        bde_pred_value = row.get('bde_pred', None)\n",
    "        bdfe_pred_value = row.get('bdfe_pred', None)\n",
    "        bond_index_value = row.get('bond_index', None)\n",
    "        \n",
    "        # Convert them to integers if needed\n",
    "        # (In practice, you may need to handle missing or invalid indexes carefully)\n",
    "        \n",
    "        # We'll define a helper function to check if an index is \"heavy\" or \"hydrogen\"\n",
    "        def is_heavy(idx):\n",
    "            return (0 <= idx < base_mol.GetNumAtoms())\n",
    "        \n",
    "        # Determine the \"types\" of s and e\n",
    "        s_is_heavy = is_heavy(s)\n",
    "        e_is_heavy = is_heavy(e)\n",
    "\n",
    "        if s_is_heavy and e_is_heavy:\n",
    "            # This is a heavy–heavy bond.\n",
    "            # If it already exists in G, update attributes.\n",
    "            if G.has_edge(s, e):\n",
    "                # Just update the existing edge\n",
    "                G[s][e]['bde_pred'] = bde_pred_value\n",
    "                G[s][e]['bdfe_pred'] = bdfe_pred_value\n",
    "                G[s][e]['bond_index'] = bond_index_value\n",
    "            else:\n",
    "                # Possibly -?> no, not possible the bond doesn't exist in the original skeleton \n",
    "                # (this can happen if the SMILES didn't have it).\n",
    "                # Add it as a new edge. This is unusual, but let's handle it anyway.\n",
    "                G.add_edge(s, e,\n",
    "                           bond_index=bond_index_value,\n",
    "                           bde_pred=bde_pred_value,\n",
    "                           bdfe_pred=bdfe_pred_value)\n",
    "\n",
    "        else:\n",
    "            # At least one of them is a \"hydrogen\" or out-of-range index\n",
    "            # We'll figure out which one is the heavy atom and which is the hydrogen.\n",
    "            if s_is_heavy and not e_is_heavy:\n",
    "                heavy_idx, hydrogen_idx = s, e\n",
    "            elif e_is_heavy and not s_is_heavy:\n",
    "                heavy_idx, hydrogen_idx = e, s\n",
    "            else:\n",
    "                # Both are hydrogens or out-of-range, which might be invalid.\n",
    "                # For safety, just skip or handle error.\n",
    "                # Could print a warning, raise an exception, etc.\n",
    "                continue\n",
    "\n",
    "            # Step 1: ensure the hydrogen node is present in G\n",
    "            # We'll generate a unique node key for the H, e.g. \"H_{hydrogen_idx}\"\n",
    "            # or something that won't collide with integer-based heavy nodes.\n",
    "            # You could also store the actual integer if your system allows it.\n",
    "            h_node = f\"H_{hydrogen_idx}\"\n",
    "            if not G.has_node(h_node):\n",
    "                # Add the hydrogen node with minimal attributes\n",
    "                G.add_node(h_node,\n",
    "                           symbol='H',\n",
    "                           rdkit_idx=None)  # or some other placeholder\n",
    "\n",
    "            # Step 2: add the H–X bond or update if it already exists\n",
    "            # The heavy_idx is the integer from RDKit.\n",
    "            if not G.has_edge(heavy_idx, h_node):\n",
    "                G.add_edge(heavy_idx, h_node,\n",
    "                           bond_index=bond_index_value,\n",
    "                           bde_pred=bde_pred_value,\n",
    "                           bdfe_pred=bdfe_pred_value)\n",
    "            else:\n",
    "                # If it somehow exists, just update attributes\n",
    "                G[heavy_idx][h_node]['bde_pred'] = bde_pred_value\n",
    "                G[heavy_idx][h_node]['bdfe_pred'] = bdfe_pred_value\n",
    "                G[heavy_idx][h_node]['bond_index'] = bond_index_value\n",
    "\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_to_df(bde_graph: nx.Graph) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert the edges of bde_graph into a DataFrame with columns:\n",
    "      ['u', 'v', 'bond_index', 'graph_bde_pred', 'graph_bdfe_pred'].\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for u, v, data in bde_graph.edges(data=True):\n",
    "        rows.append({\n",
    "            'u': u,\n",
    "            'v': v,\n",
    "            'bond_index': data['bond_index'],\n",
    "            'graph_bde_pred': data.get('bde_pred', None),\n",
    "            'graph_bdfe_pred': data.get('bdfe_pred', None)\n",
    "        })\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_list = ['C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([C@@]2(CC3)C)CCCC)(C)C',\n",
    "       'C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([C@@]2(CC3)C)CCC(C)C)(C)C',\n",
    "       'C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([C@@]2(CC3)C)CC[C@@H](C)CC)(C)C',\n",
    "       'C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([C@@]2(CC3)C)CC[C@H](CCC)C)(C)C',\n",
    "       'C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([C@]2(C)CC3)CC[C@H](C)CCCCC)(C)C',\n",
    "       'C(CCC)C[C@H](C)CC[C@@H]1[C@H](CC[C@H]2[C@]1(CC[C@@H]3[C@@]2(CCCC3(C)C)C)C)C',\n",
    "       'C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([C@@]2(CC3)C)CC[C@@H](CCCC(C)C)C)(C)C',\n",
    "       'C(C[C@@H](CC[C@H]1[C@]3([C@H](CC[C@@H]1C)[C@]2(CCCC(C)(C)[C@@H]2CC3)C)C)C)CC(C)C',\n",
    "       '[C@]23(CC[C@@H]1[C@@](CCCC1(C)C)(C)[C@H]2CC[C@H]4[C@]3(CC[C@]5([C@@H]4CCC5)C)C)C',\n",
    "       '[C@]12(CC[C@@H]5[C@@]([C@H]1CC[C@H]3[C@@]2(C)CC[C@H]4[C@@]3(CCC4)C)(CCCC5(C)C)C)C',\n",
    "       'CC[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C',\n",
    "       'CCC[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C',\n",
    "       'CCC(C)[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C',\n",
    "       'CC[C@@H](C)[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C',\n",
    "       'CCCC(C)[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C',\n",
    "       'CCC[C@@H](C)[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C',\n",
    "       'CCCCC(C)[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C',\n",
    "       'CCCC[C@@H](C)[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C',\n",
    "       'CCCCCC(C)[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C',\n",
    "       'CCCCC[C@@H](C)[C@@H]1CC[C@]2(C1CCC3(C2CCC4C3(CCC5C4(CCCC5(C)C)C)C)C)C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "def quote(x):\n",
    "    return urllib.parse.quote(x, safe='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Molecule CC[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n",
      "WARNING:root:Molecule CCC[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n",
      "WARNING:root:Molecule CCC(C)[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n",
      "WARNING:root:Molecule CC[C@@H](C)[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n",
      "WARNING:root:Molecule CCCC(C)[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n",
      "WARNING:root:Molecule CCC[C@@H](C)[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n",
      "WARNING:root:Molecule CCCCC(C)[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n",
      "WARNING:root:Molecule CCCC[C@@H](C)[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n",
      "WARNING:root:Molecule CCCCCC(C)[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n",
      "WARNING:root:Molecule CCCCC[C@@H](C)[C@@H]1CC[C@@]2(C)C1CCC1(C)C2CCC2C3(C)CCCC(C)(C)C3CCC21C has undefined stereochemistry\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "graphs = []  # Optionally keep a list of graphs if you want them separately\n",
    "\n",
    "for smiles in smiles_list:\n",
    "    # 1) Canonicalize and sanity-check input\n",
    "    can_smiles = canonicalize_smiles(smiles)\n",
    "    is_outlier, missing_atom, missing_bond = check_input(can_smiles)\n",
    "\n",
    "    # 2) Get DataFrame of predicted BDE/BDFE for each bond\n",
    "    bde_df = predict_bdes(can_smiles, draw=True)\n",
    "    bde_df['raw_smiles'] = smiles\n",
    "\n",
    "    # 3) Deduplicate and store any extra columns you like\n",
    "    bde_df = bde_df.drop_duplicates(['fragment1', 'fragment2']).reset_index(drop=True)\n",
    "    bde_df['smiles_link'] = bde_df.molecule.apply(quote)\n",
    "\n",
    "    # 4) Build a NetworkX graph containing predicted BDE/BDFE\n",
    "    bde_graph = create_bde_graph_selective_hs(can_smiles, bde_df)\n",
    "\n",
    "    # 5) (Optional) store the graph in the DataFrame if you want\n",
    "    #    the same graph for all rows (one per entire molecule)\n",
    "    bde_df['nx_graph'] = [bde_graph] * len(bde_df)\n",
    "\n",
    "    # 6) Append to your results\n",
    "    dfs.append(bde_df)\n",
    "    graphs.append(bde_graph)   # In case you want them in parallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all DataFrame results\n",
    "alfabet_results_022 = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>bond_index</th>\n",
       "      <th>graph_bde_pred</th>\n",
       "      <th>graph_bdfe_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.382645</td>\n",
       "      <td>75.711853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>H_23</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.077187</td>\n",
       "      <td>91.049133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.872467</td>\n",
       "      <td>71.412849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>H_27</td>\n",
       "      <td>29.0</td>\n",
       "      <td>97.163109</td>\n",
       "      <td>87.689636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.041306</td>\n",
       "      <td>70.000275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>H_28</td>\n",
       "      <td>30.0</td>\n",
       "      <td>95.392189</td>\n",
       "      <td>86.257256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>83.115479</td>\n",
       "      <td>66.995270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>H_30</td>\n",
       "      <td>32.0</td>\n",
       "      <td>94.518456</td>\n",
       "      <td>84.748627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>H_32</td>\n",
       "      <td>34.0</td>\n",
       "      <td>93.767822</td>\n",
       "      <td>84.237808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>86.171143</td>\n",
       "      <td>71.943581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>H_33</td>\n",
       "      <td>35.0</td>\n",
       "      <td>93.715736</td>\n",
       "      <td>84.072701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>H_36</td>\n",
       "      <td>38.0</td>\n",
       "      <td>98.747505</td>\n",
       "      <td>89.695900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>H_37</td>\n",
       "      <td>39.0</td>\n",
       "      <td>95.855804</td>\n",
       "      <td>86.941345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>H_40</td>\n",
       "      <td>42.0</td>\n",
       "      <td>94.971001</td>\n",
       "      <td>85.988342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>H_41</td>\n",
       "      <td>43.0</td>\n",
       "      <td>86.859306</td>\n",
       "      <td>75.766243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>79.460541</td>\n",
       "      <td>64.253860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11</td>\n",
       "      <td>H_44</td>\n",
       "      <td>46.0</td>\n",
       "      <td>97.184883</td>\n",
       "      <td>88.282654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12</td>\n",
       "      <td>H_46</td>\n",
       "      <td>48.0</td>\n",
       "      <td>95.408737</td>\n",
       "      <td>86.714401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>H_47</td>\n",
       "      <td>49.0</td>\n",
       "      <td>92.920944</td>\n",
       "      <td>84.154495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>14</td>\n",
       "      <td>H_49</td>\n",
       "      <td>51.0</td>\n",
       "      <td>89.283226</td>\n",
       "      <td>79.903214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>15.0</td>\n",
       "      <td>82.408630</td>\n",
       "      <td>67.338509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16</td>\n",
       "      <td>H_52</td>\n",
       "      <td>54.0</td>\n",
       "      <td>98.126953</td>\n",
       "      <td>89.117233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>18</td>\n",
       "      <td>H_56</td>\n",
       "      <td>58.0</td>\n",
       "      <td>96.827782</td>\n",
       "      <td>87.840210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>19</td>\n",
       "      <td>H_59</td>\n",
       "      <td>61.0</td>\n",
       "      <td>95.608147</td>\n",
       "      <td>86.592361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>20</td>\n",
       "      <td>H_61</td>\n",
       "      <td>63.0</td>\n",
       "      <td>96.082130</td>\n",
       "      <td>87.054794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>21.0</td>\n",
       "      <td>79.644073</td>\n",
       "      <td>64.361122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>22</td>\n",
       "      <td>H_62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>97.762428</td>\n",
       "      <td>88.862091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     u     v  bond_index  graph_bde_pred  graph_bdfe_pred\n",
       "0    0     1         0.0       89.382645        75.711853\n",
       "1    0  H_23        25.0      100.077187        91.049133\n",
       "2    1     2         1.0       85.872467        71.412849\n",
       "3    1  H_27        29.0       97.163109        87.689636\n",
       "4    2     3         2.0       85.041306        70.000275\n",
       "5    2  H_28        30.0       95.392189        86.257256\n",
       "6    3     4         3.0       83.115479        66.995270\n",
       "7    3  H_30        32.0       94.518456        84.748627\n",
       "8    4     5         NaN             NaN              NaN\n",
       "9    4    10         NaN             NaN              NaN\n",
       "10   4  H_32        34.0       93.767822        84.237808\n",
       "11   5     6         5.0       86.171143        71.943581\n",
       "12   5     7         NaN             NaN              NaN\n",
       "13   5  H_33        35.0       93.715736        84.072701\n",
       "14   6  H_36        38.0       98.747505        89.695900\n",
       "15   7     8         NaN             NaN              NaN\n",
       "16   7  H_37        39.0       95.855804        86.941345\n",
       "17   8     9         NaN             NaN              NaN\n",
       "18   8  H_40        42.0       94.971001        85.988342\n",
       "19   9    10         NaN             NaN              NaN\n",
       "20   9    21         NaN             NaN              NaN\n",
       "21   9  H_41        43.0       86.859306        75.766243\n",
       "22  10    11        10.0       79.460541        64.253860\n",
       "23  10    12         NaN             NaN              NaN\n",
       "24  11  H_44        46.0       97.184883        88.282654\n",
       "25  12    13         NaN             NaN              NaN\n",
       "26  12  H_46        48.0       95.408737        86.714401\n",
       "27  13    14         NaN             NaN              NaN\n",
       "28  13  H_47        49.0       92.920944        84.154495\n",
       "29  14    15         NaN             NaN              NaN\n",
       "30  14    21         NaN             NaN              NaN\n",
       "31  14  H_49        51.0       89.283226        79.903214\n",
       "32  15    16        15.0       82.408630        67.338509\n",
       "33  15    17         NaN             NaN              NaN\n",
       "34  15    18         NaN             NaN              NaN\n",
       "35  16  H_52        54.0       98.126953        89.117233\n",
       "36  18    19         NaN             NaN              NaN\n",
       "37  18  H_56        58.0       96.827782        87.840210\n",
       "38  19    20         NaN             NaN              NaN\n",
       "39  19  H_59        61.0       95.608147        86.592361\n",
       "40  20    21         NaN             NaN              NaN\n",
       "41  20  H_61        63.0       96.082130        87.054794\n",
       "42  21    22        21.0       79.644073        64.361122\n",
       "43  22  H_62        64.0       97.762428        88.862091"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_to_df(graphs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from jinja2->torch) (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-geometric in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from torch-geometric) (3.11.11)\n",
      "Requirement already satisfied: fsspec in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from torch-geometric) (2024.12.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from torch-geometric) (3.1.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from torch-geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from torch-geometric) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from torch-geometric) (3.2.1)\n",
      "Requirement already satisfied: requests in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from torch-geometric) (4.66.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from aiohttp->torch-geometric) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from aiohttp->torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from aiohttp->torch-geometric) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from aiohttp->torch-geometric) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from aiohttp->torch-geometric) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from aiohttp->torch-geometric) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from aiohttp->torch-geometric) (1.18.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from jinja2->torch-geometric) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from requests->torch-geometric) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from requests->torch-geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from requests->torch-geometric) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule</th>\n",
       "      <th>bond_index</th>\n",
       "      <th>bond_type</th>\n",
       "      <th>start_atom</th>\n",
       "      <th>end_atom</th>\n",
       "      <th>fragment1</th>\n",
       "      <th>fragment2</th>\n",
       "      <th>is_valid_stereo</th>\n",
       "      <th>bde_pred</th>\n",
       "      <th>bdfe_pred</th>\n",
       "      <th>bde</th>\n",
       "      <th>bdfe</th>\n",
       "      <th>set</th>\n",
       "      <th>svg</th>\n",
       "      <th>has_dft_bde</th>\n",
       "      <th>raw_smiles</th>\n",
       "      <th>smiles_link</th>\n",
       "      <th>nx_graph</th>\n",
       "      <th>temperature</th>\n",
       "      <th>Concentration</th>\n",
       "      <th>Time</th>\n",
       "      <th>Seawater</th>\n",
       "      <th>degradation_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCCC[C@@H]1[C@@H](C)CC[C@H]2[C@@]1(C)CC[C@H]1C...</td>\n",
       "      <td>10</td>\n",
       "      <td>C-C</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>CCCC[C@H]1[C]2CC[C@H]3C(C)(C)CCC[C@]3(C)[C@H]2...</td>\n",
       "      <td>[CH3]</td>\n",
       "      <td>True</td>\n",
       "      <td>79.460541</td>\n",
       "      <td>64.253860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;?xml version='1.0' encoding='iso-8859-1'?&gt;\\n&lt;...</td>\n",
       "      <td>False</td>\n",
       "      <td>C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([...</td>\n",
       "      <td>CCCC%5BC%40%40H%5D1%5BC%40%40H%5D%28C%29CC%5BC...</td>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>17.100400</td>\n",
       "      <td>74.768569</td>\n",
       "      <td>105.829650</td>\n",
       "      <td>sea</td>\n",
       "      <td>0.565740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCCC[C@@H]1[C@@H](C)CC[C@H]2[C@@]1(C)CC[C@H]1C...</td>\n",
       "      <td>21</td>\n",
       "      <td>C-C</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>CCCC[C@@H]1[C@@H](C)CC[C@@H]2[C]3CCCC(C)(C)[C@...</td>\n",
       "      <td>[CH3]</td>\n",
       "      <td>True</td>\n",
       "      <td>79.644073</td>\n",
       "      <td>64.361122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;?xml version='1.0' encoding='iso-8859-1'?&gt;\\n&lt;...</td>\n",
       "      <td>False</td>\n",
       "      <td>C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([...</td>\n",
       "      <td>CCCC%5BC%40%40H%5D1%5BC%40%40H%5D%28C%29CC%5BC...</td>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>37.021220</td>\n",
       "      <td>14.677846</td>\n",
       "      <td>47.242317</td>\n",
       "      <td>fresh</td>\n",
       "      <td>0.756477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCCC[C@@H]1[C@@H](C)CC[C@H]2[C@@]1(C)CC[C@H]1C...</td>\n",
       "      <td>15</td>\n",
       "      <td>C-C</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>CCCC[C@@H]1[C@@H](C)CC[C@H]2[C@@]1(C)CC[C@H]1[...</td>\n",
       "      <td>[CH3]</td>\n",
       "      <td>True</td>\n",
       "      <td>82.408630</td>\n",
       "      <td>67.338509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;?xml version='1.0' encoding='iso-8859-1'?&gt;\\n&lt;...</td>\n",
       "      <td>False</td>\n",
       "      <td>C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([...</td>\n",
       "      <td>CCCC%5BC%40%40H%5D1%5BC%40%40H%5D%28C%29CC%5BC...</td>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>19.830141</td>\n",
       "      <td>55.215225</td>\n",
       "      <td>4.104363</td>\n",
       "      <td>sea</td>\n",
       "      <td>0.650062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCCC[C@@H]1[C@@H](C)CC[C@H]2[C@@]1(C)CC[C@H]1C...</td>\n",
       "      <td>3</td>\n",
       "      <td>C-C</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[CH2]CCC</td>\n",
       "      <td>C[C@@H]1[CH][C@]2(C)CC[C@H]3C(C)(C)CCC[C@]3(C)...</td>\n",
       "      <td>True</td>\n",
       "      <td>83.115479</td>\n",
       "      <td>66.995270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;?xml version='1.0' encoding='iso-8859-1'?&gt;\\n&lt;...</td>\n",
       "      <td>False</td>\n",
       "      <td>C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([...</td>\n",
       "      <td>CCCC%5BC%40%40H%5D1%5BC%40%40H%5D%28C%29CC%5BC...</td>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>18.269300</td>\n",
       "      <td>77.855803</td>\n",
       "      <td>70.923872</td>\n",
       "      <td>sea</td>\n",
       "      <td>0.887023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCCC[C@@H]1[C@@H](C)CC[C@H]2[C@@]1(C)CC[C@H]1C...</td>\n",
       "      <td>2</td>\n",
       "      <td>C-C</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[CH2]CC</td>\n",
       "      <td>[CH2][C@@H]1[C@@H](C)CC[C@H]2[C@@]1(C)CC[C@H]1...</td>\n",
       "      <td>True</td>\n",
       "      <td>85.041306</td>\n",
       "      <td>70.000275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;?xml version='1.0' encoding='iso-8859-1'?&gt;\\n&lt;...</td>\n",
       "      <td>False</td>\n",
       "      <td>C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([...</td>\n",
       "      <td>CCCC%5BC%40%40H%5D1%5BC%40%40H%5D%28C%29CC%5BC...</td>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>27.142742</td>\n",
       "      <td>76.564347</td>\n",
       "      <td>22.651805</td>\n",
       "      <td>sea</td>\n",
       "      <td>0.748602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            molecule  bond_index bond_type  \\\n",
       "0  CCCC[C@@H]1[C@@H](C)CC[C@H]2[C@@]1(C)CC[C@H]1C...          10       C-C   \n",
       "1  CCCC[C@@H]1[C@@H](C)CC[C@H]2[C@@]1(C)CC[C@H]1C...          21       C-C   \n",
       "2  CCCC[C@@H]1[C@@H](C)CC[C@H]2[C@@]1(C)CC[C@H]1C...          15       C-C   \n",
       "3  CCCC[C@@H]1[C@@H](C)CC[C@H]2[C@@]1(C)CC[C@H]1C...           3       C-C   \n",
       "4  CCCC[C@@H]1[C@@H](C)CC[C@H]2[C@@]1(C)CC[C@H]1C...           2       C-C   \n",
       "\n",
       "   start_atom  end_atom                                          fragment1  \\\n",
       "0          10        11  CCCC[C@H]1[C]2CC[C@H]3C(C)(C)CCC[C@]3(C)[C@H]2...   \n",
       "1          21        22  CCCC[C@@H]1[C@@H](C)CC[C@@H]2[C]3CCCC(C)(C)[C@...   \n",
       "2          15        16  CCCC[C@@H]1[C@@H](C)CC[C@H]2[C@@]1(C)CC[C@H]1[...   \n",
       "3           3         4                                           [CH2]CCC   \n",
       "4           2         3                                            [CH2]CC   \n",
       "\n",
       "                                           fragment2  is_valid_stereo  \\\n",
       "0                                              [CH3]             True   \n",
       "1                                              [CH3]             True   \n",
       "2                                              [CH3]             True   \n",
       "3  C[C@@H]1[CH][C@]2(C)CC[C@H]3C(C)(C)CCC[C@]3(C)...             True   \n",
       "4  [CH2][C@@H]1[C@@H](C)CC[C@H]2[C@@]1(C)CC[C@H]1...             True   \n",
       "\n",
       "    bde_pred  bdfe_pred  bde  bdfe  set  \\\n",
       "0  79.460541  64.253860  NaN   NaN  NaN   \n",
       "1  79.644073  64.361122  NaN   NaN  NaN   \n",
       "2  82.408630  67.338509  NaN   NaN  NaN   \n",
       "3  83.115479  66.995270  NaN   NaN  NaN   \n",
       "4  85.041306  70.000275  NaN   NaN  NaN   \n",
       "\n",
       "                                                 svg  has_dft_bde  \\\n",
       "0  <?xml version='1.0' encoding='iso-8859-1'?>\\n<...        False   \n",
       "1  <?xml version='1.0' encoding='iso-8859-1'?>\\n<...        False   \n",
       "2  <?xml version='1.0' encoding='iso-8859-1'?>\\n<...        False   \n",
       "3  <?xml version='1.0' encoding='iso-8859-1'?>\\n<...        False   \n",
       "4  <?xml version='1.0' encoding='iso-8859-1'?>\\n<...        False   \n",
       "\n",
       "                                          raw_smiles  \\\n",
       "0  C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([...   \n",
       "1  C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([...   \n",
       "2  C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([...   \n",
       "3  C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([...   \n",
       "4  C1CC([C@H]3[C@@](C1)(C)[C@H]2CC[C@H](C)[C@H]([...   \n",
       "\n",
       "                                         smiles_link  \\\n",
       "0  CCCC%5BC%40%40H%5D1%5BC%40%40H%5D%28C%29CC%5BC...   \n",
       "1  CCCC%5BC%40%40H%5D1%5BC%40%40H%5D%28C%29CC%5BC...   \n",
       "2  CCCC%5BC%40%40H%5D1%5BC%40%40H%5D%28C%29CC%5BC...   \n",
       "3  CCCC%5BC%40%40H%5D1%5BC%40%40H%5D%28C%29CC%5BC...   \n",
       "4  CCCC%5BC%40%40H%5D1%5BC%40%40H%5D%28C%29CC%5BC...   \n",
       "\n",
       "                                            nx_graph  temperature  \\\n",
       "0  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...    17.100400   \n",
       "1  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...    37.021220   \n",
       "2  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...    19.830141   \n",
       "3  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...    18.269300   \n",
       "4  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...    27.142742   \n",
       "\n",
       "   Concentration        Time Seawater  degradation_rate  \n",
       "0      74.768569  105.829650      sea          0.565740  \n",
       "1      14.677846   47.242317    fresh          0.756477  \n",
       "2      55.215225    4.104363      sea          0.650062  \n",
       "3      77.855803   70.923872      sea          0.887023  \n",
       "4      76.564347   22.651805      sea          0.748602  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming the environment variable\n",
    "\n",
    "# 1) Add random environment columns for demonstration\n",
    "num_rows = len(alfabet_results_022)\n",
    "\n",
    "# Temperatures between 10°C and 40°C\n",
    "alfabet_results_022['temperature'] = np.random.uniform(10, 40, size=num_rows)\n",
    "\n",
    "# Concentration in mg/L, random 1–100\n",
    "alfabet_results_022['Concentration'] = np.random.uniform(1, 100, size=num_rows)\n",
    "\n",
    "# Time in hours, random 0–120\n",
    "alfabet_results_022['Time'] = np.random.uniform(0, 120, size=num_rows)\n",
    "\n",
    "# Categorical 'Seawater' vs 'fresh' environment\n",
    "alfabet_results_022['Seawater'] = np.random.choice(['sea', 'fresh'], size=num_rows)\n",
    "\n",
    "# And a random target: 'degradation_rate' (arbitrary range)\n",
    "alfabet_results_022['degradation_rate'] = np.random.uniform(0.1, 1.0, size=num_rows)\n",
    "\n",
    "# 2) Inspect the updated DataFrame\n",
    "alfabet_results_022.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def encode_environment(df):\n",
    "    \"\"\"\n",
    "    Convert 'Seawater' column to numeric (sea=1, fresh=0).\n",
    "    Return DataFrame with a new column 'sea_numeric'.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['sea_numeric'] = df['Seawater'].map({'sea': 1.0, 'fresh': 0.0})\n",
    "    return df\n",
    "\n",
    "# Encode 'Seawater' as numeric\n",
    "alfabet_results_022 = encode_environment(alfabet_results_022)\n",
    "\n",
    "# Define the environment columns we want to use as numeric\n",
    "env_columns = ['temperature', 'Concentration', 'Time', 'sea_numeric']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Custom Environmental “Positional” Encoding\n",
    "Below is a small module EnvPositionalEncoding that converts the environment variables into an embedding of size d_model. We then add that embedding to each node embedding in a batch (similar to how standard Transformers add a sinusoidal vector to each token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class EnvPositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Map environment variables to a d_model-sized embedding that will be added\n",
    "    to each node (token) embedding in the Transformer input.\n",
    "    \"\"\"\n",
    "    def __init__(self, env_dim, d_model):\n",
    "        super().__init__()\n",
    "        # A simple 2-layer MLP, for example\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(env_dim, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, d_model)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, env):\n",
    "        \"\"\"\n",
    "        x: shape (batch_size, seq_len, d_model)\n",
    "        env: shape (batch_size, env_dim) [the environment variables]\n",
    "        Return: (batch_size, seq_len, d_model) with env-based offsets added.\n",
    "        \"\"\"\n",
    "        # Convert env to (batch_size, d_model)\n",
    "        env_enc = self.linear(env)  # shape: (batch_size, d_model)\n",
    "        \n",
    "        # Unsqueeze to broadcast across seq_len\n",
    "        env_enc = env_enc.unsqueeze(1)  # (batch_size, 1, d_model)\n",
    "        \n",
    "        # Add to each node embedding\n",
    "        out = x + env_enc  # shape: (batch_size, seq_len, d_model)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Building the Model (Transformer + Environmental Encoding)\n",
    "Below is a toy example of a Transformer-based model in plain PyTorch (not PyTorch Geometric) that:\n",
    "\n",
    "Converts node symbols into embeddings (nn.Embedding).\n",
    "Adds your environment-based encoding via EnvPositionalEncoding.\n",
    "Passes it through a standard TransformerEncoder.\n",
    "Pools (e.g., average) or takes the [CLS]-like node as the molecule representation.\n",
    "Predicts the degradation rate via a small MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class MoleculeTransformerModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_atom_types,    # e.g. size of your symbol_to_index dict\n",
    "                 d_model=128, \n",
    "                 nhead=4, \n",
    "                 dim_feedforward=256, \n",
    "                 num_encoder_layers=3,\n",
    "                 env_dim=4,         # e.g. [temp, time, concentration, is_seawater?]\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # (1) Node embedding: convert each atom index to an embedding\n",
    "        self.atom_emb = nn.Embedding(num_atom_types, d_model)\n",
    "        \n",
    "        # (2) Environmental encoding\n",
    "        self.env_pos_enc = EnvPositionalEncoding(env_dim, d_model)\n",
    "        \n",
    "        # (3) Transformer encoder\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, \n",
    "                                                 nhead, \n",
    "                                                 dim_feedforward,\n",
    "                                                 dropout,\n",
    "                                                 batch_first=True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, \n",
    "                                                      num_layers=num_encoder_layers)\n",
    "        \n",
    "        # (4) A readout for regression\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, 1)  # predict a single value: degradation rate\n",
    "        )\n",
    "        \n",
    "    def forward(self, node_features, env_data):\n",
    "        \"\"\"\n",
    "        node_features: (batch_size, seq_len) of atom indices\n",
    "        env_data: (batch_size, env_dim)\n",
    "        \"\"\"\n",
    "        # 1) Convert node indices -> embeddings\n",
    "        #    shape => (batch_size, seq_len, d_model)\n",
    "        x = self.atom_emb(node_features)\n",
    "        \n",
    "        # 2) Add environment-based \"positional\" encoding\n",
    "        x = self.env_pos_enc(x, env_data)  # shape => (batch_size, seq_len, d_model)\n",
    "        \n",
    "        # 3) Pass through Transformer\n",
    "        x = self.transformer_encoder(x)  # shape => (batch_size, seq_len, d_model)\n",
    "        \n",
    "        # 4) Pool or take the first token as a \"molecule representation\"\n",
    "        #    Let's do a simple mean pool:\n",
    "        mol_repr = x.mean(dim=1)  # shape => (batch_size, d_model)\n",
    "        \n",
    "        # 5) Regress to a single value\n",
    "        out = self.mlp(mol_repr)  # shape => (batch_size, 1)\n",
    "        return out.squeeze(-1)    # shape => (batch_size,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Training Loop (MSE Loss, RMSE Metric)\n",
    "Below is an example of how you might train this model on your dataset. We’ll define a small function to compute RMSE for logging/evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(pred, target):\n",
    "    return torch.sqrt(torch.mean((pred - target)**2))\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, device='cpu'):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for node_feats, env_data, y in dataloader:\n",
    "        node_feats = node_feats.to(device)\n",
    "        env_data = env_data.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # Forward\n",
    "        preds = model(node_feats, env_data)\n",
    "        loss = F.mse_loss(preds, y)  # MSE\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * len(y)\n",
    "        \n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, device='cpu'):\n",
    "    model.eval()\n",
    "    total_mse = 0.0\n",
    "    total_count = 0\n",
    "    for node_feats, env_data, y in dataloader:\n",
    "        node_feats = node_feats.to(device)\n",
    "        env_data = env_data.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        preds = model(node_feats, env_data)\n",
    "        # MSE\n",
    "        mse_val = F.mse_loss(preds, y, reduction='sum').item()\n",
    "        total_mse += mse_val\n",
    "        total_count += len(y)\n",
    "        \n",
    "    mse_score = total_mse / total_count\n",
    "    rmse_score = np.sqrt(mse_score)\n",
    "    return mse_score, rmse_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "dataset = MoleculeEnvDataset(alfabet_results_022)\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 16\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'networkx.classes.graph.Graph'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Train for 20 epochs\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m----> 9\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     mse_score, rmse_score \u001b[38;5;241m=\u001b[39m evaluate(model, dataloader, device)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Train MSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Eval MSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Eval RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[94], line 7\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, dataloader, optimizer, device)\u001b[0m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      6\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node_feats, env_data, y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m      8\u001b[0m     node_feats \u001b[38;5;241m=\u001b[39m node_feats\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m     env_data \u001b[38;5;241m=\u001b[39m env_data\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:211\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    212\u001b[0m         collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 212\u001b[0m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\80710\\anaconda3\\envs\\alfabet-env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:240\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m             \u001b[38;5;66;03m# The sequence type may not support `copy()` / `__setitem__(index, item)`\u001b[39;00m\n\u001b[0;32m    234\u001b[0m             \u001b[38;5;66;03m# or `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[0;32m    235\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    236\u001b[0m                 collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[0;32m    237\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    238\u001b[0m             ]\n\u001b[1;32m--> 240\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'networkx.classes.graph.Graph'>"
     ]
    }
   ],
   "source": [
    "model = MoleculeTransformerModel(num_atom_types=10, d_model=64, env_dim=len(env_columns))\n",
    "model.to(device)\n",
    "    \n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "# Train for 20 epochs\n",
    "for epoch in range(20):\n",
    "    train_loss = train_one_epoch(model, dataloader, optimizer, device)\n",
    "    mse_score, rmse_score = evaluate(model, dataloader, device)\n",
    "        \n",
    "    print(f\"Epoch {epoch:02d} | Train MSE: {train_loss:.4f} | Eval MSE: {mse_score:.4f} | Eval RMSE: {rmse_score:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alfabet-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
